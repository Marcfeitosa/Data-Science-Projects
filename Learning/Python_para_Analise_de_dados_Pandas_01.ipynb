{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python para Análise de Dados - Pandas  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos trabalhar com base de imóveis que obtive no site **Kaggle**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o Pandas.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo uma base de dados no formato .csv.\n",
    "# o parâmetro sep é usado para definir qual o separador entre os dados.\n",
    "# o parâmetro header informo em qual linha está minhas colunas ou se elas não existem.\n",
    "# Se não existe colunas (header=None) o pandas dará um número para cada atributo da base.\n",
    "arquivo = 'kc_house_data.csv'\n",
    "dataset = pd.read_csv(arquivo, sep=',' ,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo o tipo da variável dataset\n",
    "# Dataframe é um estrutura de dados onde linhas podem ter colunas de diferentes tipos.\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo head() imprime as 5 linhas iniciais do dataframe.\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parâmetro index_col informa a coluna na qual o dataframe será indexado\n",
    "dataset = pd.read_csv(arquivo, sep=',', index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(arquivo, sep=',', usecols=['id','date','price','bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo head() imprime as 5 linhas iniciais do dataframe.\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo a 100 primeiras linhas do dataframe.\n",
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributo columns retorna o nome das colunas do dataframe.\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método count() retorna a quantidade de linhas de todas as colunas.\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Método describe() exibe informações estatísticas da base de dados. \n",
    "# Várias informações como desvio padrão, média, valor mínimo e valor máximo de colunas.\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as 5 ultimas linhas .\n",
    "dataset.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime uma amostra aleatória do dataset.\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna em formato de tupla a quantidade de linhas e colunas do dataset.\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime informações sobre colunas e uso de memória.\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando um Dataframe com Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instalando o Pandas Profiling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lendo o arquivo de dados e construindo o dataframe chamado df*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = 'kc_house_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(arquivo, sep=',' ,header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Usando o Profiling no jupyter notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df, check_correlation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gerando um relatorio **html**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalhando com Grandes Arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Quando estamos trabalhando com _**Grandes Arquivos**_ temos um desafio um grande desafio que é gerenciar a memória.\n",
    "+ As vezes precisamos manipular uma base de dados muito grande e por isso precisamos trabalhar com arquivos de forma diferente.\n",
    "* Uma forma é ler esses arquivos de forma limitada para não consumir toda a _**memória**_ do servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo as 5 primeiras linhas do arquivo.\n",
    "dataset = pd.read_csv(arquivo, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parâmetro chunksize define em quantas linhas cada bloco irá conter.\n",
    "chunk = pd.read_csv(arquivo, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo tamanho das partes do arquivo chunk.\n",
    "for parte in chunk:\n",
    "    print (len(parte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parâmetro chunksize define em quantas linhas cada bloco irá conter.\n",
    "chunk = pd.read_csv(arquivo, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interese sobre cada parte do dataframe em seguida adicione o valor processado a uma nova coluna do dataset.\n",
    "lista = []\n",
    "for parte in chunk:\n",
    "    lista.append(parte['bedrooms'] * 2)\n",
    "\n",
    "dataset['bedrooms_size'] = pd.concat(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mais recursos para trabalhar com grandes bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   Tente trabalhar apenas com as colunas que você vai realmente precisar.\n",
    "2.   Atente para o tipo de dado de cada coluna.\n",
    "3.   Visualize qual o separador usado para separar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dica:** Se estiver no linux use o comando head para ler as 5 primeiras linhas do arquivo:\n",
    "\n",
    "`head -n 5 dataset.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 /home/rodrigo/kc_house_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dica**: Se estiver no Windows abra o prompt do **PowerShell** e use o comando abaixo:\n",
    "- gc log.txt -head 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lear a base com o parâmetro nrows\n",
    "df = pd.read_csv('kc_house_data.csv', sep=',', nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exporte o nome das colunas para usar no parâmetro usecols*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kc_house_data.csv\", usecols=['id','date','price','bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*lendo as colunas por posições*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kc_house_data.csv\", usecols=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ler o arquivo completo e veja o uso de memória*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kc_house_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Leia todas as colunas exceto algumas..*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(data, usecols = lambda column : column not in ['sqft_living','sqft_lot','floors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalhe com os tipos de dados adequados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Atenção para os tipos de dados **object**\n",
    "- Dados que são categóricos podem receber o tipo de dados *category*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Convertendo os tipos de dados*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex = df.Sex.astype('category')\n",
    "df.Embarked = df.Embarked.astype('category')\n",
    "df.Survived = df.Survived.astype('category')\n",
    "df.Pclass = df.Pclass.astype('category')\n",
    "df.PassengerId = df.PassengerId.astype('int32')\n",
    "df.Parch = df.Parch.astype('int32')\n",
    "df.SibSp = df.SibSp.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Veja o uso de memória*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quase **50%** e ganho de memória !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Converta colunas em tempo de leitura*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(data,  dtype = {\"Embarked\" : \"category\", \"Survived\": \"category\", \"Parch\": \"int32\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultando um Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos fazer _**consultas**_ em um Dataframe, isso se assemelha a linhagem SQL.\n",
    "\n",
    "* Existem métodos interessantes para fazer consultas usando operadores lógicos (>,<,== ).\n",
    "\n",
    "* Além disso podemos fazer consultas usando instruções de agrupamento, por exemplo. \n",
    "\n",
    "* Isso da muita flexibilidade para o Cientista de dados na hora de explorar da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta a quantidade de valores únicos\n",
    "pd.value_counts(dataset['bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método loc() é usado para visualizar informações do dataset.\n",
    "# Este método recebe uma lista por parâmetro e retorna o resultado da consulta.\n",
    "# Consulta imóveis com 3 quartos\n",
    "dataset.loc[dataset['bedrooms'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método loc() junto com o operador &\n",
    "# Consulta imóveis com 3 quartos e com o número de banheiros maior que 2\n",
    "dataset.loc[(dataset['bedrooms']==3) & (dataset['bathrooms'] > 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método sort_values() ordena o dataset pela coluna 'price' em ordem descrescente.\n",
    "# Apenas o retorno da query será ordenado, não a organização do dataset.\n",
    "dataset.sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método count() para contar o número de linhas de uma query.\n",
    "dataset[dataset['bedrooms']==4].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alterando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando uma coluna ao Dataframe.\n",
    "dataset['size'] = (dataset['bedrooms'] * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o conteúdo da coluna criada.\n",
    "dataset['size'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma função para processamento de dados.\n",
    "def categoriza(s):\n",
    "    if s >= 80:\n",
    "        return 'Big'\n",
    "    elif s >= 60:\n",
    "        return 'Medium'\n",
    "    elif s >= 40:\n",
    "        return 'Small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma nova coluna a partir do processamento realizado.\n",
    "dataset['cat_size'] = dataset['size'].apply(categoriza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a nova coluna criada.\n",
    "dataset['cat_size'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver a distribuicao da coluna com o método value_counts.\n",
    "pd.value_counts(dataset['cat_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método drop é usado para excluir dados no dataframe.\n",
    "# A opção axis=1 define que queremos excluir uma coluna e não uma linha.\n",
    "# O parâmetro inplace define que a alteração irá modificar o objeto em memória.\n",
    "\n",
    "dataset.drop(['cat_size'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna 'size'\n",
    "dataset.drop(['size'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataset.\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apagando linhas baseado em Condições lógicas!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropa linhas com bedrooms = 0\n",
    "dataset.drop(dataset[dataset.bedrooms==0].index ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropa linhas maiores que 30\n",
    "dataset.drop(dataset[dataset.bedrooms>30].index ,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percorrendo linhas de um Dataframe Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Método iterrows() permite percorrer por todas as linhas de um dataframe.\n",
    "- Esse método retorna um objeto **iterator** que contém o indice de cada linha e um cada linha em um dado do tipo série."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime a primeira linha do objeto iterator\n",
    "next(dataset.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrendo o dataframe e imprimindo o indice e cada linha.\n",
    "for indice, linha in dataset.head(10).iterrows():\n",
    "     print(indice, linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrendo o dataframe e acessando colunas nomes.\n",
    "for indice, linha in dataset.head(10).iterrows():\n",
    "     print(indice, linha['bedrooms'], linha['floors'], linha['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atualizando Dataframe ao percorrer linha a linha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime os 5 primeiros valores de preços antes da atualização.\n",
    "dataset.price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrendo e atualizando linhas de um dataframe.\n",
    "# Atualiza o valor da coluna PRICE multiplicando seu valor por 2.\n",
    "# é preciso usar o método at()\n",
    "for indice, linha in dataset.iterrows():\n",
    "    dataset.at[indice , 'price'] = linha['price'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percorrendo um dataframe com o método itertuples()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retorna as linhas e índice em formato de tuplas.\n",
    "- Costuma ser mais rápido que o iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorre o dataframe usando itertuples()\n",
    "for linha in dataset.head().itertuples():\n",
    "    print(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime linhas chamando as colunas por nome.\n",
    "for linha in dataset.head().itertuples():\n",
    "    print(linha.id, linha.bedrooms, linha.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Missing Values** são valores faltantes em colunas, esses podem ser oriundos de falhas em cargas de dados, falhas em crawlers ou até mesmo corrupção de dados.\n",
    "\n",
    "* Missing Values podem ser um problema em várias situações, como por exemplo, algoritmos de machine learning que não trabalham bem com dados faltantes.\n",
    "\n",
    "* Estes também podem atrapalhar resultados de análises.\n",
    "\n",
    "* Vamos aprender como encontrar missing values na base de dados e como manipular esses valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = '/home/rodrigo/curso/Python Para Data Análise/kc_house_data.csv'\n",
    "dataset = pd.read_csv(arquivo, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultando linhas com valores faltantes.\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Com este comando removemos todas as linhas onde tenha pela menos um registro faltante em algum atributo.\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possível ainda, remover somente linhas que estejam com valores faltantes em todas as colunas, veja:\n",
    "dataset.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preenche com a media dos valores da coluns floors os values null\n",
    "dataset['floors'].fillna(dataset['floors'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preenche com 1 os values null da coluna bedrooms\n",
    "dataset['bedrooms'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota em um gŕafico de barras o preço dos imóveis\n",
    "%matplotlib notebook\n",
    "dataset['price'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota em gráfico de dispersão o preço e o numero de quartos de imóveis\n",
    "dataset.plot(x='bedrooms',y='price',kind='scatter', title='Bedrooms x Price',color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota em gráfico de dispersão o preço e o número de banheiros\n",
    "dataset.plot(x='bathrooms',y='price',kind='scatter',color='y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
