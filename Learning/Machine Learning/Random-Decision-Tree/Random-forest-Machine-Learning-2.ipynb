{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a72a75-c2e2-464d-868b-e95e63175e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b9721-7e8c-4705-a3a6-85c195a93d8a",
   "metadata": {},
   "source": [
    "Carregando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f6c5ca-2238-44d7-99b2-01f3a025fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu = pd.read_csv(r\"C:\\Users\\marcf\\OneDrive\\Documentos\\Ciencia de dados\\Árvores de decisão e Florestas Aleatórias\\random-forest-materiais-apoio\\xAPI-Edu-Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94536959-6161-4018-8f25-0743eb1dab14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>70</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>MiddleSchool</td>\n",
       "      <td>G-07</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>MiddleSchool</td>\n",
       "      <td>G-07</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>MiddleSchool</td>\n",
       "      <td>G-07</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>MiddleSchool</td>\n",
       "      <td>G-07</td>\n",
       "      <td>B</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>70</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender NationalITy PlaceofBirth       StageID GradeID SectionID Topic  \\\n",
       "0      M          KW       KuwaIT    lowerlevel    G-04         A    IT   \n",
       "1      M          KW       KuwaIT    lowerlevel    G-04         A    IT   \n",
       "2      M          KW       KuwaIT    lowerlevel    G-04         A    IT   \n",
       "3      M          KW       KuwaIT    lowerlevel    G-04         A    IT   \n",
       "4      M          KW       KuwaIT    lowerlevel    G-04         A    IT   \n",
       "5      F          KW       KuwaIT    lowerlevel    G-04         A    IT   \n",
       "6      M          KW       KuwaIT  MiddleSchool    G-07         A  Math   \n",
       "7      M          KW       KuwaIT  MiddleSchool    G-07         A  Math   \n",
       "8      F          KW       KuwaIT  MiddleSchool    G-07         A  Math   \n",
       "9      F          KW       KuwaIT  MiddleSchool    G-07         B    IT   \n",
       "\n",
       "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "2        F   Father           10                 7                  0   \n",
       "3        F   Father           30                25                  5   \n",
       "4        F   Father           40                50                 12   \n",
       "5        F   Father           42                30                 13   \n",
       "6        F   Father           35                12                  0   \n",
       "7        F   Father           50                10                 15   \n",
       "8        F   Father           12                21                 16   \n",
       "9        F   Father           70                80                 25   \n",
       "\n",
       "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "2          30                    No                      Bad   \n",
       "3          35                    No                      Bad   \n",
       "4          50                    No                      Bad   \n",
       "5          70                   Yes                      Bad   \n",
       "6          17                    No                      Bad   \n",
       "7          22                   Yes                     Good   \n",
       "8          50                   Yes                     Good   \n",
       "9          70                   Yes                     Good   \n",
       "\n",
       "  StudentAbsenceDays Class  \n",
       "0            Under-7     M  \n",
       "1            Under-7     M  \n",
       "2            Above-7     L  \n",
       "3            Above-7     L  \n",
       "4            Above-7     M  \n",
       "5            Above-7     M  \n",
       "6            Above-7     L  \n",
       "7            Under-7     M  \n",
       "8            Under-7     M  \n",
       "9            Under-7     M  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f85eb0-6599-4a96-9370-a00eb89679c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.775000</td>\n",
       "      <td>54.797917</td>\n",
       "      <td>37.918750</td>\n",
       "      <td>43.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.779223</td>\n",
       "      <td>33.080007</td>\n",
       "      <td>26.611244</td>\n",
       "      <td>27.637735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       raisedhands  VisITedResources  AnnouncementsView  Discussion\n",
       "count   480.000000        480.000000         480.000000  480.000000\n",
       "mean     46.775000         54.797917          37.918750   43.283333\n",
       "std      30.779223         33.080007          26.611244   27.637735\n",
       "min       0.000000          0.000000           0.000000    1.000000\n",
       "25%      15.750000         20.000000          14.000000   20.000000\n",
       "50%      50.000000         65.000000          33.000000   39.000000\n",
       "75%      75.000000         84.000000          58.000000   70.000000\n",
       "max     100.000000         99.000000          98.000000   99.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acb5a3-fad6-4f3b-bc3a-77b461dfdec1",
   "metadata": {},
   "source": [
    "Verificando as distribuições de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01e323c-42ee-4f8e-b818-89445cf0009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    211\n",
       "H    142\n",
       "L    127\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69daed-9a44-44d1-a991-135cfaad4966",
   "metadata": {},
   "source": [
    "Verificando os registros nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6dc5024-b546-4a04-ab7b-972f2065b3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                      0\n",
       "NationalITy                 0\n",
       "PlaceofBirth                0\n",
       "StageID                     0\n",
       "GradeID                     0\n",
       "SectionID                   0\n",
       "Topic                       0\n",
       "Semester                    0\n",
       "Relation                    0\n",
       "raisedhands                 0\n",
       "VisITedResources            0\n",
       "AnnouncementsView           0\n",
       "Discussion                  0\n",
       "ParentAnsweringSurvey       0\n",
       "ParentschoolSatisfaction    0\n",
       "StudentAbsenceDays          0\n",
       "Class                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b759e2-a30e-4c10-a956-74e94bf863e5",
   "metadata": {},
   "source": [
    "Codificando os atributos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112a925d-8cb9-45b1-8c43-5a154d47fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = df_edu\n",
    "Cat_Columns = Features.dtypes.pipe(lambda Features: Features[Features=='object']).index\n",
    "for col in Cat_Columns:\n",
    "    label = LabelEncoder()\n",
    "    Features[col] = label.fit_transform(Features[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26193b72-463e-4369-9d25-c15ff97b87b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  NationalITy  PlaceofBirth  StageID  GradeID  SectionID  Topic  \\\n",
       "0       1            4             4        2        1          0      7   \n",
       "1       1            4             4        2        1          0      7   \n",
       "2       1            4             4        2        1          0      7   \n",
       "3       1            4             4        2        1          0      7   \n",
       "4       1            4             4        2        1          0      7   \n",
       "\n",
       "   Semester  Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0         0         0           15                16                  2   \n",
       "1         0         0           20                20                  3   \n",
       "2         0         0           10                 7                  0   \n",
       "3         0         0           30                25                  5   \n",
       "4         0         0           40                50                 12   \n",
       "\n",
       "   Discussion  ParentAnsweringSurvey  ParentschoolSatisfaction  \\\n",
       "0          20                      1                         1   \n",
       "1          25                      1                         1   \n",
       "2          30                      0                         0   \n",
       "3          35                      0                         0   \n",
       "4          50                      0                         0   \n",
       "\n",
       "   StudentAbsenceDays  Class  \n",
       "0                   1      2  \n",
       "1                   1      2  \n",
       "2                   0      1  \n",
       "3                   0      1  \n",
       "4                   0      2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a497c67-64a5-454b-ba32-21595b3e456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.635417</td>\n",
       "      <td>4.345833</td>\n",
       "      <td>4.397917</td>\n",
       "      <td>1.345833</td>\n",
       "      <td>2.906250</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>5.256250</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.410417</td>\n",
       "      <td>46.775000</td>\n",
       "      <td>54.797917</td>\n",
       "      <td>37.918750</td>\n",
       "      <td>43.283333</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.602083</td>\n",
       "      <td>1.143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.481815</td>\n",
       "      <td>2.469265</td>\n",
       "      <td>2.628334</td>\n",
       "      <td>0.603732</td>\n",
       "      <td>2.464267</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>3.388388</td>\n",
       "      <td>0.500413</td>\n",
       "      <td>0.492423</td>\n",
       "      <td>30.779223</td>\n",
       "      <td>33.080007</td>\n",
       "      <td>26.611244</td>\n",
       "      <td>27.637735</td>\n",
       "      <td>0.496596</td>\n",
       "      <td>0.488632</td>\n",
       "      <td>0.489979</td>\n",
       "      <td>0.846312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gender  NationalITy  PlaceofBirth     StageID     GradeID  \\\n",
       "count  480.000000   480.000000    480.000000  480.000000  480.000000   \n",
       "mean     0.635417     4.345833      4.397917    1.345833    2.906250   \n",
       "std      0.481815     2.469265      2.628334    0.603732    2.464267   \n",
       "min      0.000000     0.000000      0.000000    0.000000    0.000000   \n",
       "25%      0.000000     3.000000      3.000000    1.000000    0.000000   \n",
       "50%      1.000000     4.000000      4.000000    1.000000    4.000000   \n",
       "75%      1.000000     4.000000      4.000000    2.000000    5.000000   \n",
       "max      1.000000    13.000000     13.000000    2.000000    9.000000   \n",
       "\n",
       "        SectionID       Topic    Semester    Relation  raisedhands  \\\n",
       "count  480.000000  480.000000  480.000000  480.000000   480.000000   \n",
       "mean     0.472917    5.256250    0.489583    0.410417    46.775000   \n",
       "std      0.612411    3.388388    0.500413    0.492423    30.779223   \n",
       "min      0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "25%      0.000000    3.000000    0.000000    0.000000    15.750000   \n",
       "50%      0.000000    5.000000    0.000000    0.000000    50.000000   \n",
       "75%      1.000000    7.000000    1.000000    1.000000    75.000000   \n",
       "max      2.000000   11.000000    1.000000    1.000000   100.000000   \n",
       "\n",
       "       VisITedResources  AnnouncementsView  Discussion  ParentAnsweringSurvey  \\\n",
       "count        480.000000         480.000000  480.000000             480.000000   \n",
       "mean          54.797917          37.918750   43.283333               0.562500   \n",
       "std           33.080007          26.611244   27.637735               0.496596   \n",
       "min            0.000000           0.000000    1.000000               0.000000   \n",
       "25%           20.000000          14.000000   20.000000               0.000000   \n",
       "50%           65.000000          33.000000   39.000000               1.000000   \n",
       "75%           84.000000          58.000000   70.000000               1.000000   \n",
       "max           99.000000          98.000000   99.000000               1.000000   \n",
       "\n",
       "       ParentschoolSatisfaction  StudentAbsenceDays       Class  \n",
       "count                480.000000          480.000000  480.000000  \n",
       "mean                   0.608333            0.602083    1.143750  \n",
       "std                    0.488632            0.489979    0.846312  \n",
       "min                    0.000000            0.000000    0.000000  \n",
       "25%                    0.000000            0.000000    0.000000  \n",
       "50%                    1.000000            1.000000    1.000000  \n",
       "75%                    1.000000            1.000000    2.000000  \n",
       "max                    1.000000            1.000000    2.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186a70f-5b86-4998-966d-f01da2a0312f",
   "metadata": {},
   "source": [
    "Separando os dados e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66aedf26-4407-41b2-991d-3ded196f402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_edu.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24fb3d02-78a4-4b07-8b7d-9d9d575a4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df_edu['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052155b-deb5-4000-b21c-64360eaf1edc",
   "metadata": {},
   "source": [
    "# Random Forest vs Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e696a15-3309-4854-a427-b90878ad2701",
   "metadata": {},
   "source": [
    "Resultados Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73509066-bd3a-4b09-9a11-86eae369b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf = RandomForestClassifier(random_state=1,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29f2b9f4-5723-4b44-a705-b0353e2372c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_random = cross_val_predict(random_clf, dataset,classes,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b6e4695-5540-40f3-b1d6-d24acb084151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65       142\n",
      "           1       0.77      0.78      0.77       127\n",
      "           2       0.63      0.63      0.63       211\n",
      "\n",
      "    accuracy                           0.67       480\n",
      "   macro avg       0.68      0.68      0.68       480\n",
      "weighted avg       0.67      0.67      0.67       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9bc6c-e1ff-4c99-aea3-608e400439f5",
   "metadata": {},
   "source": [
    "Resultados Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9c2259d-de19-4b28-8d13-be8bb3aebd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "181072ed-59d2-44e6-88c7-4adeba7245ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e4cc50b-8219-4c63-897f-d13a0c0091b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_tree = cross_val_predict(tree_clf, dataset,classes,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2a7a01e-f34f-4ea4-a509-f2d55acfd996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55       142\n",
      "           1       0.74      0.68      0.70       127\n",
      "           2       0.54      0.49      0.52       211\n",
      "\n",
      "    accuracy                           0.57       480\n",
      "   macro avg       0.59      0.59      0.59       480\n",
      "weighted avg       0.58      0.57      0.58       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca002b1-dc58-48c9-bfc5-ba603977efc7",
   "metadata": {},
   "source": [
    "Verificando Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "336d4864-9b18-474b-9dfe-09e9afe5108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_edu.drop('Class', axis=1),\n",
    "                                                    df_edu['Class'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84143b4d-d499-4403-85bf-21b62ccb449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_random_forest(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state=1)\n",
    "    else:\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state=1, max_depth=maxdepth)\n",
    "    rf.fit(x_train, y_train)\n",
    "    train_score = rf.score(x_train, y_train)\n",
    "    test_score = rf.score(x_test, y_test)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65e936ad-9c93-4434-882a-c69b7c32d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training Score       Testing Score       \n",
      "-----      --------------       -------------       \n",
      "1         (0.6666666666666666, 0.5486111111111112)\n",
      "2         (0.75, 0.6180555555555556)\n",
      "3         (0.8244047619047619, 0.6805555555555556)\n",
      "4         (0.8720238095238095, 0.7152777777777778)\n",
      "5         (0.8958333333333334, 0.75)\n",
      "6         (0.9345238095238095, 0.7847222222222222)\n",
      "7         (0.9702380952380952, 0.7916666666666666)\n",
      "8         (0.9821428571428571, 0.7638888888888888)\n",
      "9         (1.0, 0.7847222222222222)\n",
      "10        (1.0, 0.7569444444444444)\n",
      "11        (1.0, 0.7916666666666666)\n",
      "12        (1.0, 0.7986111111111112)\n",
      "13        (1.0, 0.7847222222222222)\n",
      "14        (1.0, 0.7986111111111112)\n",
      "15        (1.0, 0.7986111111111112)\n",
      "Full      (1.0, 0.7986111111111112)\n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training Score', 'Testing Score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------', '-------------'))\n",
    "depth = range(1,16)\n",
    "\n",
    "for profundidade in depth:\n",
    "    if profundidade < 10:\n",
    "        print('{:1}         {}'.format(profundidade,str(compara_modelos_random_forest(profundidade))))\n",
    "    else:\n",
    "        print('{:1}        {}'.format(profundidade,str(compara_modelos_random_forest(profundidade))))\n",
    "        \n",
    "print('{:1}      {}'.format('Full',str(compara_modelos_random_forest(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fe462d3-ea3c-4aee-8721-f069cca3b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_random_forest_discrepancy(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state=1)\n",
    "    else:\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state=1, max_depth=maxdepth)\n",
    "    rf.fit(x_train, y_train)\n",
    "    train_score = rf.score(x_train, y_train)\n",
    "    test_score = rf.score(x_test, y_test)\n",
    "    return train_score - test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8d8d76e-194c-41f6-8422-320f5f73d22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training Score       Testing Score        Discrepancy Training x Testing\n",
      "-----      --------------       -------------        ------------------------------\n",
      "1         (0.6666666666666666, 0.5486111111111112)   0.11805555555555547\n",
      "2         (0.75, 0.6180555555555556)   0.13194444444444442\n",
      "3         (0.8244047619047619, 0.6805555555555556)   0.14384920634920628\n",
      "4         (0.8720238095238095, 0.7152777777777778)   0.15674603174603174\n",
      "5         (0.8958333333333334, 0.75)   0.14583333333333337\n",
      "6         (0.9345238095238095, 0.7847222222222222)   0.14980158730158732\n",
      "7         (0.9702380952380952, 0.7916666666666666)   0.1785714285714286\n",
      "8         (0.9821428571428571, 0.7638888888888888)   0.21825396825396826\n",
      "9         (1.0, 0.7847222222222222)   0.2152777777777778\n",
      "10        (1.0, 0.7569444444444444)    0.24305555555555558\n",
      "11        (1.0, 0.7916666666666666)    0.20833333333333337\n",
      "12        (1.0, 0.7986111111111112)    0.20138888888888884\n",
      "13        (1.0, 0.7847222222222222)    0.2152777777777778\n",
      "14        (1.0, 0.7986111111111112)    0.20138888888888884\n",
      "15        (1.0, 0.7986111111111112)    0.20138888888888884\n",
      "Full      (1.0, 0.7986111111111112)    0.20138888888888884\n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20} {:20}'.format('depth', 'Training Score', 'Testing Score', 'Discrepancy Training x Testing'))\n",
    "print('{:10} {:20} {:20} {:20}'.format('-----', '--------------', '-------------', '------------------------------'))\n",
    "depth = range(1,16)\n",
    "\n",
    "for profundidade in depth:\n",
    "    if profundidade < 10:\n",
    "        print('{:1}         {}   {}'.format(profundidade,str(compara_modelos_random_forest(profundidade)),\n",
    "                                       compara_modelos_random_forest_discrepancy(profundidade)\n",
    "                                      )\n",
    "             )\n",
    "    else:\n",
    "        print('{:1}        {}    {}'.format(profundidade,str(compara_modelos_random_forest(profundidade)),\n",
    "                                      compara_modelos_random_forest_discrepancy(profundidade)\n",
    "                                     )\n",
    "             )\n",
    "        \n",
    "print('{:1}      {}    {}'.format('Full',str(compara_modelos_random_forest(0)),\n",
    "                            compara_modelos_random_forest_discrepancy(0)\n",
    "                           )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7111e513-07be-4b80-8dd2-93523e82963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_decision_tree(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        df = DecisionTreeClassifier(random_state=1)\n",
    "    else:\n",
    "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
    "    df.fit(x_train, y_train)\n",
    "    train_score = df.score(x_train, y_train)\n",
    "    test_score = df.score(x_test, y_test)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "baf3932d-9f27-4833-967d-b5de74839dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training Score       Testing Score       \n",
      "-----      --------------       -------------       \n",
      "1         (0.5892857142857143, 0.5)\n",
      "2         (0.6398809523809523, 0.6805555555555556)\n",
      "3         (0.7321428571428571, 0.7013888888888888)\n",
      "4         (0.7916666666666666, 0.7430555555555556)\n",
      "5         (0.8690476190476191, 0.6805555555555556)\n",
      "6         (0.8988095238095238, 0.7152777777777778)\n",
      "7         (0.9404761904761905, 0.7152777777777778)\n",
      "8         (0.9702380952380952, 0.7083333333333334)\n",
      "9         (0.9821428571428571, 0.6875)\n",
      "10        (0.9910714285714286, 0.6875)\n",
      "11        (0.9940476190476191, 0.6944444444444444)\n",
      "12        (1.0, 0.6944444444444444)\n",
      "13        (1.0, 0.6944444444444444)\n",
      "14        (1.0, 0.6944444444444444)\n",
      "15        (1.0, 0.6944444444444444)\n",
      "Full      (1.0, 0.6944444444444444)\n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training Score', 'Testing Score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------', '-------------'))\n",
    "depth = range(1,16)\n",
    "\n",
    "for profundidade in depth:\n",
    "    if profundidade < 10:\n",
    "        print('{:1}         {}'.format(profundidade,str(compara_modelos_decision_tree(profundidade))))\n",
    "    else:\n",
    "        print('{:1}        {}'.format(profundidade,str(compara_modelos_decision_tree(profundidade))))\n",
    "        \n",
    "print('{:1}      {}'.format('Full',str(compara_modelos_decision_tree(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd4fe6f2-42e8-4ff8-a438-9c57a69ada08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_decision_tree_discrepancy(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        df = DecisionTreeClassifier(random_state=1)\n",
    "    else:\n",
    "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
    "    df.fit(x_train, y_train)\n",
    "    train_score = df.score(x_train, y_train)\n",
    "    test_score = df.score(x_test, y_test)\n",
    "    return train_score - test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afd0c3b5-be31-4284-b0a3-33bb5772c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training Score       Testing Score        Discrepancy Training x Testing\n",
      "-----      --------------       -------------        ------------------------------\n",
      "1         (0.5892857142857143, 0.5)   0.0892857142857143\n",
      "2         (0.6398809523809523, 0.6805555555555556)   -0.04067460317460325\n",
      "3         (0.7321428571428571, 0.7013888888888888)   0.030753968253968256\n",
      "4         (0.7916666666666666, 0.7430555555555556)   0.04861111111111105\n",
      "5         (0.8690476190476191, 0.6805555555555556)   0.1884920634920635\n",
      "6         (0.8988095238095238, 0.7152777777777778)   0.18353174603174605\n",
      "7         (0.9404761904761905, 0.7152777777777778)   0.22519841269841268\n",
      "8         (0.9702380952380952, 0.7083333333333334)   0.26190476190476186\n",
      "9         (0.9821428571428571, 0.6875)   0.2946428571428571\n",
      "10        (0.9910714285714286, 0.6875)    0.3035714285714286\n",
      "11        (0.9940476190476191, 0.6944444444444444)    0.29960317460317465\n",
      "12        (1.0, 0.6944444444444444)    0.3055555555555556\n",
      "13        (1.0, 0.6944444444444444)    0.3055555555555556\n",
      "14        (1.0, 0.6944444444444444)    0.3055555555555556\n",
      "15        (1.0, 0.6944444444444444)    0.3055555555555556\n",
      "Full      (1.0, 0.6944444444444444)    0.3055555555555556\n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20} {:20}'.format('depth', 'Training Score', 'Testing Score', 'Discrepancy Training x Testing'))\n",
    "print('{:10} {:20} {:20} {:20}'.format('-----', '--------------', '-------------', '------------------------------'))\n",
    "depth = range(1,16)\n",
    "\n",
    "for profundidade in depth:\n",
    "    if profundidade < 10:\n",
    "        print('{:1}         {}   {}'.format(profundidade,str(compara_modelos_decision_tree(profundidade)),\n",
    "                                            compara_modelos_decision_tree_discrepancy(profundidade)\n",
    "                                      )\n",
    "             )\n",
    "    else:\n",
    "        print('{:1}        {}    {}'.format(profundidade,str(compara_modelos_decision_tree(profundidade)),\n",
    "                                            compara_modelos_decision_tree_discrepancy(profundidade)\n",
    "                                     )\n",
    "             )\n",
    "        \n",
    "print('{:1}      {}    {}'.format('Full',str(compara_modelos_decision_tree(0)),\n",
    "                                  compara_modelos_decision_tree_discrepancy(0)\n",
    "                           )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "34909999-1b4b-45f7-9a48-c8571ce8523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_random_forest_classifier(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state=1)\n",
    "    else:\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state=1, max_depth=maxdepth)\n",
    "    rf.fit(x_train, y_train)\n",
    "    train_score = rf.score(x_train, y_train)\n",
    "    test_score = rf.score(x_test, y_test)\n",
    "    if (train_score - test_score) < 0.10:\n",
    "        classificador = 'Não sofre overfitting'\n",
    "    else:\n",
    "        classificador = 'Sofre overfitting'\n",
    "    return classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1d57c9d1-7ddc-4b20-bdce-c6e199124570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training Score       Testing Score        Discrepancy Training x Testing Overfitting         \n",
      "-----      --------------       -------------        ------------------------------ -----------         \n",
      "1         (0.6666666666666666, 0.5486111111111112)   0.11805555555555547             Sofre overfitting\n",
      "2         (0.75, 0.6180555555555556)   0.13194444444444442             Sofre overfitting\n",
      "3         (0.8244047619047619, 0.6805555555555556)   0.14384920634920628             Sofre overfitting\n",
      "4         (0.8720238095238095, 0.7152777777777778)   0.15674603174603174             Sofre overfitting\n",
      "5         (0.8958333333333334, 0.75)   0.14583333333333337             Sofre overfitting\n",
      "6         (0.9345238095238095, 0.7847222222222222)   0.14980158730158732             Sofre overfitting\n",
      "7         (0.9702380952380952, 0.7916666666666666)   0.1785714285714286             Sofre overfitting\n",
      "8         (0.9821428571428571, 0.7638888888888888)   0.21825396825396826             Sofre overfitting\n",
      "9         (1.0, 0.7847222222222222)   0.2152777777777778             Sofre overfitting\n",
      "10        (1.0, 0.7569444444444444)    0.24305555555555558             Sofre overfitting\n",
      "11        (1.0, 0.7916666666666666)    0.20833333333333337             Sofre overfitting\n",
      "12        (1.0, 0.7986111111111112)    0.20138888888888884             Sofre overfitting\n",
      "13        (1.0, 0.7847222222222222)    0.2152777777777778             Sofre overfitting\n",
      "14        (1.0, 0.7986111111111112)    0.20138888888888884             Sofre overfitting\n",
      "15        (1.0, 0.7986111111111112)    0.20138888888888884             Sofre overfitting\n",
      "Full      (1.0, 0.7986111111111112)    0.20138888888888884           Sofre overfitting\n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20} {:20} {:20}'.format('depth', 'Training Score', 'Testing Score', 'Discrepancy Training x Testing', 'Overfitting'))\n",
    "print('{:10} {:20} {:20} {:20} {:20}'.format('-----', '--------------', '-------------', '------------------------------', '-----------'))\n",
    "depth = range(1,16)\n",
    "\n",
    "for profundidade in depth:\n",
    "    if profundidade < 10:\n",
    "        print('{:1}         {}   {}             {}'.format(profundidade,\n",
    "                                                           str(compara_modelos_random_forest(profundidade)),\n",
    "                                                           compara_modelos_random_forest_discrepancy(profundidade),\n",
    "                                                           compara_modelos_random_forest_classifier(profundidade)\n",
    "                                      )\n",
    "             )\n",
    "    else:\n",
    "        print('{:1}        {}    {}             {}'.format(profundidade,\n",
    "                                                           str(compara_modelos_random_forest(profundidade)),\n",
    "                                                           compara_modelos_random_forest_discrepancy(profundidade),\n",
    "                                                           compara_modelos_random_forest_classifier(profundidade)\n",
    "                                     )\n",
    "             )\n",
    "        \n",
    "print('{:1}      {}    {}           {}'.format('Full',\n",
    "                                               str(compara_modelos_random_forest(0)),\n",
    "                                               compara_modelos_random_forest_discrepancy(0),\n",
    "                                               compara_modelos_random_forest_classifier(0)\n",
    "                           )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4224d91b-8f13-464b-a0a8-ed7b1d238b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_decision_tree_classifier(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        df = DecisionTreeClassifier(random_state=1)\n",
    "    else:\n",
    "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
    "    df.fit(x_train, y_train)\n",
    "    train_score = df.score(x_train, y_train)\n",
    "    test_score = df.score(x_test, y_test)\n",
    "    if (train_score - test_score) < 0.10:\n",
    "        classificador = 'Não sofre overfitting'\n",
    "    else:\n",
    "        classificador = 'Sofre overfitting'\n",
    "    return classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ae5b7f3-8e58-46e8-b20b-4f72e4b98d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training Score       Testing Score        Discrepancy Training x Testing Overfitting         \n",
      "-----      --------------       -------------        ------------------------------ -----------         \n",
      "1         (0.5892857142857143, 0.5)   0.0892857142857143             Não sofre overfitting\n",
      "2         (0.6398809523809523, 0.6805555555555556)   -0.04067460317460325             Não sofre overfitting\n",
      "3         (0.7321428571428571, 0.7013888888888888)   0.030753968253968256             Não sofre overfitting\n",
      "4         (0.7916666666666666, 0.7430555555555556)   0.04861111111111105             Não sofre overfitting\n",
      "5         (0.8690476190476191, 0.6805555555555556)   0.1884920634920635             Sofre overfitting\n",
      "6         (0.8988095238095238, 0.7152777777777778)   0.18353174603174605             Sofre overfitting\n",
      "7         (0.9404761904761905, 0.7152777777777778)   0.22519841269841268             Sofre overfitting\n",
      "8         (0.9702380952380952, 0.7083333333333334)   0.26190476190476186             Sofre overfitting\n",
      "9         (0.9821428571428571, 0.6875)   0.2946428571428571             Sofre overfitting\n",
      "10        (0.9910714285714286, 0.6875)    0.3035714285714286             Sofre overfitting\n",
      "11        (0.9940476190476191, 0.6944444444444444)    0.29960317460317465             Sofre overfitting\n",
      "12        (1.0, 0.6944444444444444)    0.3055555555555556             Sofre overfitting\n",
      "13        (1.0, 0.6944444444444444)    0.3055555555555556             Sofre overfitting\n",
      "14        (1.0, 0.6944444444444444)    0.3055555555555556             Sofre overfitting\n",
      "15        (1.0, 0.6944444444444444)    0.3055555555555556             Sofre overfitting\n",
      "Full      (1.0, 0.6944444444444444)    0.3055555555555556           Sofre overfitting\n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20} {:20} {:20}'.format('depth', 'Training Score', 'Testing Score', 'Discrepancy Training x Testing', 'Overfitting'))\n",
    "print('{:10} {:20} {:20} {:20} {:20}'.format('-----', '--------------', '-------------', '------------------------------', '-----------'))\n",
    "depth = range(1,16)\n",
    "\n",
    "for profundidade in depth:\n",
    "    if profundidade < 10:\n",
    "        print('{:1}         {}   {}             {}'.format(profundidade,\n",
    "                                                           str(compara_modelos_decision_tree(profundidade)),\n",
    "                                                           compara_modelos_decision_tree_discrepancy(profundidade),\n",
    "                                                           compara_modelos_decision_tree_classifier(profundidade)\n",
    "                                      )\n",
    "             )\n",
    "    else:\n",
    "        print('{:1}        {}    {}             {}'.format(profundidade,\n",
    "                                                           str(compara_modelos_decision_tree(profundidade)),\n",
    "                                                           compara_modelos_decision_tree_discrepancy(profundidade),\n",
    "                                                           compara_modelos_decision_tree_classifier(profundidade)\n",
    "                                     )\n",
    "             )\n",
    "        \n",
    "print('{:1}      {}    {}           {}'.format('Full',\n",
    "                                               str(compara_modelos_decision_tree(0)),\n",
    "                                               compara_modelos_decision_tree_discrepancy(0),\n",
    "                                               compara_modelos_decision_tree_classifier(0)\n",
    "                           )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b8545-9b0c-444b-86eb-eb7d8395a455",
   "metadata": {},
   "source": [
    "## Tunning do Modelo para garantir o melhor Desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240aa1d-c830-4282-91d8-1eb5ad7d8857",
   "metadata": {},
   "source": [
    "Como encontrar os melhores valores para os parâmetros do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58095fd4-0ced-4baa-89c8-b23c3dbc90c9",
   "metadata": {},
   "source": [
    "RandomForestClassifier(n_estimators=?, criterion='gini' ou 'entropy', max_depth=?, min_samples_split=?, min_samples_leaf=?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "044da81f-3d03-44a6-b797-a8dca5c24a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4b0b8-5d91-4a14-85c9-b6363401f5c0",
   "metadata": {},
   "source": [
    "Lista de possíveis valores de estimators ou quantidade de árvores da floresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "704e16f7-4aff-4933-8193-c24f868147ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_estimators = [10, 20, 50, 100, 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380eb90-22c0-4803-b568-c29b4602e97f",
   "metadata": {},
   "source": [
    "Lista de possíveis valores para o critério de divisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e7873a5-8540-491e-a057-9d418df1cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76950393-43af-47dc-857c-1a0543556563",
   "metadata": {},
   "source": [
    "Lista de possíveis valores para a profundidade máxima de cada árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e59831bd-314e-4bc7-a03f-0efc09767275",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_max_depth = [10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd2811-590a-4198-b27b-c437193e398b",
   "metadata": {},
   "source": [
    "Lista de possíveis valores para os parametros min_samples_split e min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f706f51-67eb-4ab5-8ba1-2d8d319a90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_min_samples_split = [2, 5, 10, 15]\n",
    "valores_min_samples_leaf = [1, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c1742-e474-4b6c-b944-1a83c661af07",
   "metadata": {},
   "source": [
    "Define um dicionário que recebe as listas de parâmetros e valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e640f33a-d1b8-4ff4-846c-eb1b8fd87b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = dict(n_estimators=valores_estimators,\n",
    "                       criterion=valores_criterion,\n",
    "                       max_depth=valores_max_depth,\n",
    "                       min_samples_split=valores_min_samples_split,\n",
    "                       min_samples_leaf=valores_min_samples_leaf\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f96ef7-386e-4630-846f-3e9429a758b0",
   "metadata": {},
   "source": [
    "Dicionário com os parametros que serão utilizados no grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e4349182-86cd-4402-b636-304891cc1073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 20, 50, 100, 150],\n",
       " 'criterion': ['gini', 'entropy'],\n",
       " 'max_depth': [10, 20, 50, 100],\n",
       " 'min_samples_split': [2, 5, 10, 15],\n",
       " 'min_samples_leaf': [1, 5, 10, 15]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametros_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289968f1-1afc-4e85-b3dc-5deaf6674b06",
   "metadata": {},
   "source": [
    "Instancia o GridSearch com o modelo a ser utilizado, parametros, número de folds e scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "102190be-ff03-460b-9866-f009e7bf5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9a1a9908-3172-4955-927d-63051680e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(rf, parametros_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fa54d-d2da-4bab-975e-bd92d48ad5e6",
   "metadata": {},
   "source": [
    "Aplica o GridSearch passando as features e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f4a2d22e-21e1-444a-a18f-8a0534f8cd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 50, 100],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10, 15],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100, 150]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 50, 100],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10, 15],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100, 150]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 50, 100],\n",
       "                         'min_samples_leaf': [1, 5, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 10, 15],\n",
       "                         'n_estimators': [10, 20, 50, 100, 150]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(df_edu.drop('Class', axis=1),df_edu['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16c733-34d8-46ce-8a11-5a1ec25ecdcc",
   "metadata": {},
   "source": [
    "Imprime os scores por combinações _(o atributo grid_scores_foi depreciado e substituído por cv_results__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c1c1dad4-61ac-4a49-812e-e8f839a3f494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02594976, 0.03519044, 0.07774415, 0.15448532, 0.22752037,\n",
       "        0.01696815, 0.03210135, 0.08163257, 0.16833849, 0.22944155,\n",
       "        0.01672754, 0.02992473, 0.07346692, 0.13915439, 0.21389318,\n",
       "        0.01628308, 0.03040805, 0.06965737, 0.13526931, 0.20361829,\n",
       "        0.01583443, 0.03059964, 0.06999364, 0.13458176, 0.20396929,\n",
       "        0.02165179, 0.0315403 , 0.07098436, 0.15144958, 0.22560511,\n",
       "        0.0227777 , 0.04522324, 0.08189516, 0.15424843, 0.21913538,\n",
       "        0.01680408, 0.03245506, 0.07557912, 0.15110092, 0.25455666,\n",
       "        0.01748114, 0.03151226, 0.08334389, 0.12912726, 0.22732415,\n",
       "        0.02178774, 0.03071399, 0.06607909, 0.1358593 , 0.22663598,\n",
       "        0.01528277, 0.02795982, 0.06477008, 0.12911482, 0.19309125,\n",
       "        0.01473837, 0.02724433, 0.06423035, 0.14070177, 0.24873271,\n",
       "        0.0150064 , 0.10936756, 0.11629677, 0.19410939, 0.27461324,\n",
       "        0.02510834, 0.05529203, 0.06918201, 0.15380554, 0.22465487,\n",
       "        0.01796622, 0.0342598 , 0.07598639, 0.14470105, 0.20087404,\n",
       "        0.01595283, 0.04125471, 0.10103364, 0.20241756, 0.21370907,\n",
       "        0.01776333, 0.03180094, 0.0893476 , 0.15741324, 0.22837443,\n",
       "        0.01657481, 0.03481483, 0.08590846, 0.22464051, 0.25773802,\n",
       "        0.01758113, 0.03433495, 0.08902402, 0.17052608, 0.25040965,\n",
       "        0.01929193, 0.03306956, 0.08019199, 0.14984956, 0.22397599,\n",
       "        0.01671638, 0.03438201, 0.07273726, 0.14262638, 0.24009724,\n",
       "        0.01748238, 0.03026648, 0.07783208, 0.14878392, 0.23135023,\n",
       "        0.01685572, 0.03355761, 0.08736386, 0.16250448, 0.23115797,\n",
       "        0.02103443, 0.03464355, 0.08296766, 0.1492816 , 0.20732031,\n",
       "        0.01689692, 0.03638258, 0.07858582, 0.13792806, 0.19879546,\n",
       "        0.01602468, 0.02954149, 0.07148032, 0.15450711, 0.21744132,\n",
       "        0.01604991, 0.03237462, 0.07158804, 0.14486628, 0.20818419,\n",
       "        0.01761947, 0.03828359, 0.07203469, 0.14421449, 0.2095952 ,\n",
       "        0.01586895, 0.02729063, 0.06854939, 0.14952435, 0.19475336,\n",
       "        0.01589241, 0.02812886, 0.08200717, 0.15919247, 0.19883251,\n",
       "        0.01893668, 0.03203554, 0.08256645, 0.13483734, 0.22292705,\n",
       "        0.01785088, 0.03280301, 0.07200465, 0.13152614, 0.19603748,\n",
       "        0.01751523, 0.03808479, 0.09018817, 0.15708933, 0.23450074,\n",
       "        0.01731544, 0.0319593 , 0.07686028, 0.16126447, 0.23545628,\n",
       "        0.02020512, 0.03125277, 0.078369  , 0.14846988, 0.22686815,\n",
       "        0.01674762, 0.03137884, 0.07293811, 0.14485717, 0.2145864 ,\n",
       "        0.01612477, 0.03153811, 0.07227335, 0.14187226, 0.21067991,\n",
       "        0.01754317, 0.03224173, 0.07514915, 0.1408421 , 0.21521397,\n",
       "        0.01684842, 0.02890425, 0.07069492, 0.13797894, 0.21735597,\n",
       "        0.01606793, 0.02899051, 0.07988787, 0.15754905, 0.2265985 ,\n",
       "        0.0171927 , 0.03011971, 0.0710824 , 0.13950973, 0.20356669,\n",
       "        0.01593518, 0.02940464, 0.07198901, 0.13366599, 0.2146502 ,\n",
       "        0.02047   , 0.03119354, 0.07807975, 0.13900042, 0.2093235 ,\n",
       "        0.01660967, 0.03537436, 0.07966986, 0.14312396, 0.22122755,\n",
       "        0.01766586, 0.03030548, 0.07235885, 0.1480989 , 0.25852151,\n",
       "        0.02279978, 0.0316361 , 0.07999358, 0.1411099 , 0.20777302,\n",
       "        0.01933103, 0.03081799, 0.06963077, 0.14241395, 0.21928158,\n",
       "        0.01631317, 0.03042555, 0.07747188, 0.14028645, 0.22158413,\n",
       "        0.01820803, 0.03486581, 0.08706846, 0.17430854, 0.23836689,\n",
       "        0.01964135, 0.03661742, 0.09259443, 0.17000389, 0.26732268,\n",
       "        0.01742487, 0.03361797, 0.08157477, 0.16004119, 0.24181752,\n",
       "        0.01687255, 0.03561635, 0.07791557, 0.16751051, 0.22389312,\n",
       "        0.0182035 , 0.03230519, 0.07509456, 0.14023676, 0.21083031,\n",
       "        0.01679387, 0.03009057, 0.07094789, 0.14468384, 0.20851874,\n",
       "        0.01621265, 0.03091335, 0.08027058, 0.15830369, 0.21068234,\n",
       "        0.01625204, 0.0323791 , 0.07484031, 0.13897462, 0.20745158,\n",
       "        0.01561699, 0.02994123, 0.07363343, 0.14020734, 0.20631003,\n",
       "        0.0161407 , 0.02932501, 0.06986675, 0.14074092, 0.22095394,\n",
       "        0.01641173, 0.02886829, 0.07072868, 0.13719192, 0.20851092,\n",
       "        0.01816325, 0.0320168 , 0.08151951, 0.13987565, 0.21345587,\n",
       "        0.01656556, 0.02834735, 0.07335076, 0.14465551, 0.2016088 ,\n",
       "        0.01750731, 0.03651853, 0.07530184, 0.13181391, 0.19163046,\n",
       "        0.01522446, 0.02903481, 0.06658254, 0.13209105, 0.19041419,\n",
       "        0.01491365, 0.0274992 , 0.06690402, 0.12477427, 0.27745848,\n",
       "        0.01780043, 0.03481731, 0.08229513, 0.16951141, 0.28043442,\n",
       "        0.02167912, 0.03734236, 0.09196758, 0.17301741, 0.25760331,\n",
       "        0.01761799, 0.03242536, 0.08788691, 0.1726069 , 0.24166832,\n",
       "        0.01801043, 0.03202972, 0.08098054, 0.15602312, 0.22491341,\n",
       "        0.01648893, 0.03212156, 0.07584133, 0.15131054, 0.22604012,\n",
       "        0.01802807, 0.03289571, 0.07461119, 0.16728787, 0.25930567,\n",
       "        0.01737843, 0.03176775, 0.09371161, 0.15871258, 0.25989819,\n",
       "        0.01675348, 0.0304285 , 0.07521915, 0.16505923, 0.22757554,\n",
       "        0.01826196, 0.03001637, 0.08268938, 0.14568577, 0.22108359,\n",
       "        0.01608887, 0.02993031, 0.07074656, 0.13992391, 0.21384692,\n",
       "        0.01572976, 0.03227067, 0.08202772, 0.1397975 , 0.21842599,\n",
       "        0.01733327, 0.02994909, 0.07073607, 0.16326952, 0.22165866,\n",
       "        0.01558394, 0.02999725, 0.0710463 , 0.13490834, 0.21510954,\n",
       "        0.0161262 , 0.02781477, 0.06747236, 0.14939437, 0.20428033,\n",
       "        0.01550231, 0.02776499, 0.07594728, 0.16518588, 0.21690001,\n",
       "        0.017799  , 0.03516941, 0.0798481 , 0.14555254, 0.23075852,\n",
       "        0.01936283, 0.03640022, 0.0970787 , 0.19341655, 0.27298813,\n",
       "        0.01911335, 0.03403144, 0.08219428, 0.16959267, 0.27001934,\n",
       "        0.01771317, 0.03609328, 0.08535452, 0.17231121, 0.23299661,\n",
       "        0.01814141, 0.03307495, 0.07876682, 0.16311741, 0.22512074,\n",
       "        0.0169868 , 0.03088713, 0.07413659, 0.14720082, 0.21894622,\n",
       "        0.01713285, 0.03314009, 0.08230453, 0.16028428, 0.24690118,\n",
       "        0.01962824, 0.03329253, 0.08200617, 0.15148377, 0.23885708,\n",
       "        0.01650805, 0.03136101, 0.07353787, 0.14569769, 0.22497091,\n",
       "        0.01731262, 0.03368611, 0.07435226, 0.14370809, 0.21493154,\n",
       "        0.01680245, 0.02909675, 0.0692214 , 0.13726926, 0.21856279,\n",
       "        0.01618557, 0.03312917, 0.07915692, 0.14637961, 0.20994005,\n",
       "        0.01675625, 0.0300571 , 0.07249861, 0.14274035, 0.20534854,\n",
       "        0.01544418, 0.02944074, 0.06872106, 0.1366436 , 0.1976706 ,\n",
       "        0.01559978, 0.03037848, 0.07566237, 0.15147948, 0.20892839,\n",
       "        0.01634831, 0.0323585 , 0.08721948, 0.15543289, 0.21708412,\n",
       "        0.01829548, 0.0327323 , 0.07692761, 0.144453  , 0.20644093,\n",
       "        0.02006998, 0.03485651, 0.09382362, 0.18359623, 0.26830125,\n",
       "        0.01783209, 0.03437786, 0.09493637, 0.18578005, 0.24075356,\n",
       "        0.01836414, 0.03652406, 0.08301535, 0.16469388, 0.22901268,\n",
       "        0.01947155, 0.03493991, 0.0833879 , 0.16717319, 0.23407445,\n",
       "        0.01708536, 0.02947497, 0.09893312, 0.16717033, 0.25007958,\n",
       "        0.02204695, 0.03148351, 0.08425064, 0.16127539, 0.26782641,\n",
       "        0.01787534, 0.03320813, 0.08409195, 0.1570334 , 0.22803493,\n",
       "        0.0174427 , 0.0315134 , 0.07371521, 0.15046744, 0.24407072,\n",
       "        0.01582856, 0.03025761, 0.07051001, 0.13730779, 0.21075482,\n",
       "        0.0173562 , 0.03133869, 0.07297983, 0.15527086, 0.23572035,\n",
       "        0.01834097, 0.03117914, 0.07884588, 0.15937872, 0.23115664,\n",
       "        0.01640649, 0.03064289, 0.06999512, 0.15393047, 0.21169019,\n",
       "        0.0151648 , 0.02811193, 0.06806517, 0.15103774, 0.21064844,\n",
       "        0.01653118, 0.02889552, 0.0690906 , 0.13570299, 0.20023208,\n",
       "        0.01585116, 0.02877989, 0.07461653, 0.15147223, 0.19977927,\n",
       "        0.01635375, 0.03013282, 0.08112235, 0.13932333, 0.21856179,\n",
       "        0.02205629, 0.04290829, 0.10000076, 0.16701961, 0.25176535,\n",
       "        0.01842995, 0.03470306, 0.08135767, 0.16289601, 0.27604561,\n",
       "        0.02105966, 0.03757024, 0.08941202, 0.17282858, 0.25375786,\n",
       "        0.01923609, 0.03891039, 0.08726964, 0.16647997, 0.24675946,\n",
       "        0.02120543, 0.03622837, 0.0885776 , 0.16124601, 0.23390784,\n",
       "        0.01692739, 0.03382344, 0.0817297 , 0.16616755, 0.22471957,\n",
       "        0.01700935, 0.03225956, 0.08574767, 0.14631271, 0.22013226,\n",
       "        0.01707125, 0.03129005, 0.07265515, 0.16270356, 0.22018399,\n",
       "        0.01586199, 0.02933955, 0.07070174, 0.1504921 , 0.2074193 ,\n",
       "        0.01616955, 0.0297791 , 0.06986532, 0.13937168, 0.20828457,\n",
       "        0.01753397, 0.02858067, 0.07020655, 0.1349926 , 0.21555395,\n",
       "        0.01796312, 0.03547287, 0.07077641, 0.1383832 , 0.20821609,\n",
       "        0.01587014, 0.02993269, 0.08295045, 0.14791408, 0.20574985,\n",
       "        0.01576004, 0.02767177, 0.06503997, 0.13660874, 0.19324517,\n",
       "        0.01487346, 0.02822404, 0.06669121, 0.12856498, 0.19815993,\n",
       "        0.01555018, 0.0284204 , 0.06689706, 0.13498058, 0.20695338]),\n",
       " 'std_fit_time': array([4.83324653e-03, 1.46468110e-03, 2.06692566e-03, 5.14544192e-03,\n",
       "        3.64084817e-03, 7.24446763e-04, 9.04972488e-04, 7.67837449e-03,\n",
       "        3.55901569e-03, 7.66511648e-03, 5.27771535e-04, 3.70610944e-04,\n",
       "        1.03319882e-03, 7.81754727e-04, 7.51503462e-03, 1.00294517e-03,\n",
       "        1.69574217e-03, 1.23197370e-03, 2.66453678e-03, 3.62171919e-03,\n",
       "        6.55073824e-04, 2.16276024e-03, 1.19414198e-03, 1.49288864e-03,\n",
       "        4.15517246e-03, 4.64080516e-03, 5.05753283e-03, 4.04554195e-03,\n",
       "        3.18585475e-03, 5.28837618e-03, 1.04128876e-02, 1.46589153e-02,\n",
       "        7.25498605e-03, 9.25426605e-03, 7.29890612e-03, 2.93289454e-04,\n",
       "        1.16304609e-03, 5.28072494e-03, 8.36432764e-03, 1.63984071e-02,\n",
       "        5.55533286e-04, 7.31249348e-04, 9.72141703e-03, 3.90031166e-03,\n",
       "        3.59683478e-02, 2.68402682e-03, 3.74652460e-03, 1.74525782e-03,\n",
       "        1.07769556e-02, 4.05086616e-03, 9.00455717e-04, 1.16425896e-03,\n",
       "        3.06725168e-04, 3.90211385e-03, 3.67605912e-03, 1.43784187e-04,\n",
       "        1.64576530e-04, 1.33633317e-03, 1.94552578e-02, 2.12357002e-02,\n",
       "        9.33881814e-04, 4.77582675e-02, 4.09570663e-02, 2.88646685e-02,\n",
       "        4.60280165e-02, 7.58018939e-03, 7.94592298e-03, 3.26268350e-03,\n",
       "        1.64462829e-02, 8.28399391e-03, 1.92725154e-03, 2.89899594e-03,\n",
       "        9.24462213e-03, 9.10361435e-03, 1.69444998e-02, 2.88795761e-03,\n",
       "        1.15844832e-02, 3.94020754e-02, 6.33370301e-02, 1.52937194e-02,\n",
       "        8.86861371e-04, 1.60117815e-03, 6.33364426e-03, 8.39818006e-03,\n",
       "        3.46895675e-03, 3.87346256e-04, 4.39162044e-03, 3.38825684e-03,\n",
       "        4.53001024e-02, 9.22160736e-03, 1.18914406e-03, 2.12182031e-03,\n",
       "        2.92885336e-03, 6.02371791e-03, 1.12674301e-02, 1.81875913e-03,\n",
       "        1.56352682e-03, 3.26822410e-03, 1.45672001e-02, 1.15192417e-02,\n",
       "        1.37931168e-03, 5.34599049e-03, 1.80723630e-03, 2.44448296e-03,\n",
       "        1.40902235e-02, 2.64079990e-03, 1.23603250e-03, 9.67925355e-03,\n",
       "        9.62794951e-03, 1.41550109e-02, 9.68970322e-04, 2.46116092e-03,\n",
       "        4.48801675e-03, 1.02442229e-02, 9.64811829e-03, 1.98880983e-03,\n",
       "        7.81638920e-04, 2.46611218e-03, 1.03435609e-02, 7.04151963e-03,\n",
       "        2.36788577e-03, 3.93176170e-03, 7.54863902e-03, 4.73499476e-03,\n",
       "        4.98014162e-03, 1.72729099e-03, 1.27195376e-03, 4.69803528e-03,\n",
       "        4.46573181e-03, 1.36876491e-02, 1.31716932e-03, 5.02796594e-03,\n",
       "        1.87722698e-03, 5.94404303e-03, 1.09311308e-02, 2.99714039e-03,\n",
       "        4.38048779e-03, 2.29585920e-03, 1.48439490e-02, 1.14992121e-02,\n",
       "        1.18513386e-03, 6.66796445e-04, 3.73685055e-03, 1.81197765e-02,\n",
       "        3.39601125e-03, 6.68066108e-04, 4.80289999e-04, 8.44438803e-03,\n",
       "        1.10055772e-03, 4.89676480e-03, 1.09413582e-03, 3.27199430e-03,\n",
       "        5.27399953e-03, 2.70468749e-03, 7.99943792e-03, 1.13469236e-03,\n",
       "        2.28744681e-03, 4.01459661e-03, 1.44876096e-03, 4.87515739e-03,\n",
       "        4.24378170e-04, 5.78077645e-03, 3.70564869e-03, 4.08015394e-04,\n",
       "        2.75726877e-03, 3.78898520e-04, 6.79010471e-04, 1.98343876e-03,\n",
       "        1.25749416e-02, 1.47516818e-02, 4.89775663e-03, 5.15593561e-04,\n",
       "        4.41744866e-03, 1.65900556e-03, 5.12416659e-03, 3.42803954e-04,\n",
       "        1.64760026e-03, 1.71731402e-03, 2.04592553e-03, 2.52694636e-03,\n",
       "        2.55724545e-04, 2.41765106e-03, 1.69321593e-03, 1.94784279e-03,\n",
       "        1.09797279e-03, 1.55149018e-03, 1.79395065e-03, 7.07579002e-03,\n",
       "        3.36533286e-03, 3.93809392e-03, 7.64908806e-04, 6.73944666e-04,\n",
       "        3.10617029e-03, 1.78856699e-03, 2.62927598e-02, 1.16733331e-03,\n",
       "        1.12019895e-03, 1.69046424e-02, 1.15375008e-02, 1.29973923e-02,\n",
       "        1.29363784e-03, 1.69738922e-03, 9.95464630e-04, 2.87140608e-03,\n",
       "        3.85429798e-03, 1.80111437e-04, 2.18507035e-03, 5.28966842e-03,\n",
       "        2.90801582e-03, 1.59133354e-02, 1.88624612e-03, 4.42154757e-04,\n",
       "        5.51798180e-03, 5.81122789e-03, 1.23726785e-02, 3.22151489e-03,\n",
       "        4.58644250e-03, 5.70766249e-03, 9.00865950e-03, 8.00188823e-03,\n",
       "        1.03793848e-03, 6.24260975e-03, 5.85777456e-03, 4.97708249e-03,\n",
       "        1.74041949e-02, 2.10930909e-03, 9.50941110e-04, 7.85757357e-03,\n",
       "        6.65303416e-03, 1.40678827e-02, 1.99816233e-03, 3.10017459e-03,\n",
       "        3.68117688e-03, 1.12566120e-02, 9.35585032e-03, 4.64044845e-04,\n",
       "        2.21097942e-03, 9.04779164e-03, 7.57695388e-03, 1.20377020e-02,\n",
       "        7.48191721e-04, 1.17384537e-03, 9.15697385e-03, 6.81131139e-03,\n",
       "        6.34851926e-03, 2.13652685e-03, 4.18096095e-03, 1.92654991e-03,\n",
       "        1.04589958e-02, 2.18435340e-02, 8.95894736e-04, 1.88668321e-03,\n",
       "        5.70888607e-03, 6.74376918e-03, 1.15405881e-02, 1.71710550e-04,\n",
       "        3.67333360e-03, 5.27299376e-03, 7.86233808e-03, 1.34906805e-02,\n",
       "        1.41298251e-03, 1.23840096e-03, 1.74836510e-03, 2.52507579e-03,\n",
       "        3.68923047e-03, 7.79962754e-04, 1.10509931e-04, 1.07941710e-03,\n",
       "        6.12334759e-03, 3.53028699e-03, 3.94294636e-04, 1.71571526e-03,\n",
       "        6.05127701e-03, 1.24877336e-02, 1.90138447e-03, 2.07303714e-04,\n",
       "        4.37272529e-03, 3.07741498e-03, 3.98922245e-03, 1.98468380e-03,\n",
       "        5.09431776e-04, 9.91546412e-04, 5.36456614e-03, 1.26424141e-02,\n",
       "        9.34741637e-03, 1.48800919e-03, 2.33929991e-03, 2.01527201e-03,\n",
       "        5.51873780e-03, 7.54802844e-03, 1.25608784e-03, 4.46719481e-04,\n",
       "        2.46764884e-03, 3.16182547e-03, 1.37472450e-02, 5.44535746e-04,\n",
       "        9.20016983e-05, 3.86559612e-03, 7.11141427e-03, 8.15058600e-03,\n",
       "        4.95420383e-04, 1.38060054e-03, 4.34518728e-03, 1.38082913e-02,\n",
       "        1.27314405e-02, 3.23242465e-03, 2.56642629e-03, 9.32801664e-03,\n",
       "        4.23232934e-03, 2.31983569e-03, 3.66935318e-04, 2.01743333e-03,\n",
       "        1.18480935e-03, 4.64759436e-03, 2.70273953e-03, 7.28080900e-04,\n",
       "        4.61801291e-04, 3.48143959e-03, 1.81181854e-03, 6.33521366e-02,\n",
       "        3.99041272e-04, 4.27365329e-03, 2.51043629e-03, 1.85110171e-02,\n",
       "        1.00025633e-02, 2.87078029e-03, 3.35394440e-03, 2.65833486e-03,\n",
       "        1.17783065e-02, 1.70440250e-02, 1.09905850e-03, 1.09794305e-03,\n",
       "        5.71987697e-03, 7.27810771e-03, 9.72068431e-03, 1.15050800e-03,\n",
       "        1.13386245e-03, 2.25355691e-03, 4.00816374e-03, 3.87250457e-03,\n",
       "        4.19682601e-04, 2.22632866e-03, 3.03202312e-03, 4.12507345e-03,\n",
       "        6.80152722e-03, 7.91409799e-04, 2.59847634e-03, 1.55475428e-03,\n",
       "        1.87770648e-02, 2.52061340e-02, 6.55068183e-04, 1.04978338e-03,\n",
       "        1.96841223e-02, 1.01374433e-02, 2.26707634e-02, 5.90762856e-04,\n",
       "        3.54164282e-04, 4.89210607e-03, 8.95038591e-03, 1.46498070e-02,\n",
       "        2.14679988e-03, 9.17909417e-04, 5.90961060e-03, 8.36150156e-03,\n",
       "        2.05958572e-02, 1.04143091e-04, 1.49318899e-03, 1.69441227e-03,\n",
       "        1.02137589e-02, 1.15673426e-02, 2.67650893e-04, 5.41744697e-03,\n",
       "        4.43538558e-03, 3.85804114e-03, 7.38541049e-03, 1.55510979e-03,\n",
       "        1.67292276e-03, 1.33726797e-03, 5.01079845e-02, 3.16502643e-02,\n",
       "        3.96818612e-04, 3.00159077e-03, 4.57111277e-03, 4.12061632e-03,\n",
       "        1.58835328e-02, 1.00445690e-03, 7.66974902e-04, 2.22713463e-03,\n",
       "        1.08507172e-02, 1.54573997e-02, 7.12251531e-04, 1.25853987e-03,\n",
       "        1.84561949e-02, 3.50990597e-02, 7.46550506e-03, 1.03164830e-03,\n",
       "        2.05399412e-03, 4.90757755e-03, 6.47735687e-03, 1.87970919e-02,\n",
       "        4.44464123e-04, 1.22773788e-03, 2.68779066e-03, 1.00784243e-02,\n",
       "        2.50863898e-02, 1.43732944e-03, 5.83982341e-04, 1.64986171e-03,\n",
       "        1.19998417e-02, 1.28223060e-02, 9.76794635e-04, 1.82285034e-03,\n",
       "        6.53934561e-03, 1.01054429e-02, 5.27107497e-03, 1.71878172e-03,\n",
       "        9.18782547e-04, 2.79450016e-03, 1.63071083e-02, 4.75992934e-03,\n",
       "        1.02075074e-03, 8.12064530e-04, 1.32527740e-03, 6.80859296e-04,\n",
       "        3.46011071e-03, 5.66284963e-04, 1.19111096e-03, 5.10158926e-03,\n",
       "        8.21543587e-03, 5.44466867e-03, 1.32602534e-03, 1.44481232e-03,\n",
       "        2.93686569e-03, 5.94741440e-03, 1.57094093e-02, 3.94327735e-04,\n",
       "        9.46716901e-04, 1.33088323e-03, 4.66931965e-03, 9.59129201e-03,\n",
       "        4.96933405e-04, 4.35437154e-03, 4.69124791e-03, 3.28546374e-03,\n",
       "        1.15193609e-02, 8.78246745e-04, 6.61608672e-04, 9.96444701e-04,\n",
       "        2.46059220e-03, 6.09243131e-03, 1.98649090e-04, 3.88016355e-03,\n",
       "        1.83535963e-03, 5.67037755e-03, 3.95287789e-03, 1.52067397e-03,\n",
       "        7.92886550e-04, 3.37058890e-03, 4.90515406e-03, 3.72152979e-03,\n",
       "        5.48712300e-04, 1.37759247e-03, 2.15400278e-03, 4.27769085e-03,\n",
       "        3.02162494e-03, 4.93240721e-04, 1.81396459e-03, 4.78943722e-03,\n",
       "        3.29296288e-03, 1.04896996e-02, 1.73240440e-03, 3.18760936e-04,\n",
       "        6.35409773e-03, 4.19653874e-03, 6.34900290e-03, 4.79934185e-03,\n",
       "        1.39640055e-03, 5.18846650e-04, 1.01400894e-02, 1.29619272e-02,\n",
       "        7.45397095e-04, 1.22015622e-03, 7.97871594e-03, 1.44164018e-02,\n",
       "        1.01075982e-02, 4.15637329e-04, 3.78071789e-03, 2.72375599e-03,\n",
       "        7.97688438e-03, 1.00672339e-02, 1.52093098e-03, 5.27375909e-03,\n",
       "        6.07735863e-03, 6.06974240e-03, 1.39658841e-02, 1.17998344e-03,\n",
       "        5.99355545e-04, 1.98715905e-03, 2.04328942e-02, 1.84913591e-02,\n",
       "        7.64975653e-04, 9.89562027e-04, 1.66813355e-02, 1.27159765e-02,\n",
       "        2.15720366e-02, 2.03499814e-03, 1.39279673e-03, 7.87375518e-03,\n",
       "        1.32986767e-02, 1.84452004e-02, 1.71421022e-03, 2.54431647e-03,\n",
       "        1.55186744e-03, 1.15569459e-02, 2.31767134e-03, 1.27363707e-03,\n",
       "        1.25333353e-03, 2.26777518e-03, 1.03096473e-02, 3.25989525e-02,\n",
       "        4.16046020e-04, 9.30810336e-04, 1.41921287e-03, 3.09162730e-03,\n",
       "        9.99931746e-03, 2.23483894e-03, 1.38166303e-03, 2.70630495e-03,\n",
       "        5.48853403e-03, 1.16073985e-02, 1.29498552e-03, 1.14076510e-03,\n",
       "        4.93901625e-03, 8.51185403e-03, 2.55175844e-02, 8.69466493e-04,\n",
       "        2.22596623e-03, 5.00906175e-04, 1.33201405e-02, 1.44163411e-02,\n",
       "        2.51794104e-04, 9.20549059e-04, 1.62176245e-03, 1.26323347e-02,\n",
       "        1.18230092e-02, 1.71562636e-03, 1.01561417e-03, 1.54382090e-03,\n",
       "        2.87405824e-03, 7.48344638e-03, 4.66859390e-04, 4.26151068e-04,\n",
       "        1.02960884e-02, 4.32212254e-03, 3.49324169e-03, 1.09489220e-03,\n",
       "        3.52636583e-03, 4.59863939e-03, 3.14594389e-03, 6.68993727e-03,\n",
       "        9.19762781e-04, 3.27823480e-03, 6.38092507e-03, 2.68315231e-03,\n",
       "        5.59890324e-03, 1.34350711e-03, 2.39483826e-03, 1.57786533e-03,\n",
       "        5.30729171e-03, 1.42161935e-02, 2.63768156e-03, 5.45398058e-04,\n",
       "        7.37949122e-03, 9.94177143e-03, 9.58351779e-03, 1.10394560e-03,\n",
       "        2.80033401e-03, 4.12053042e-03, 1.81280600e-02, 1.35549752e-02,\n",
       "        1.35581154e-03, 8.43116428e-04, 3.78347769e-03, 3.85916194e-03,\n",
       "        1.16844695e-02, 8.32724180e-04, 2.60661123e-03, 4.80860335e-03,\n",
       "        2.75488878e-03, 1.22854829e-02, 9.15600972e-04, 3.21651072e-03,\n",
       "        2.56339893e-03, 4.37697048e-03, 5.87150743e-03, 6.44989424e-04,\n",
       "        1.61203916e-03, 2.05636203e-03, 2.42414228e-03, 3.98798044e-03,\n",
       "        4.40196711e-04, 4.06589709e-04, 1.59152902e-03, 1.10914429e-02,\n",
       "        1.49957299e-03, 7.47512870e-04, 9.84911907e-04, 2.15276053e-03,\n",
       "        2.17950256e-03, 1.09195744e-02, 1.76640215e-03, 5.67149062e-04,\n",
       "        2.60040188e-04, 2.71583479e-03, 1.02974035e-02, 2.29062385e-03,\n",
       "        2.14756957e-03, 1.88556569e-03, 3.84455691e-03, 4.97490310e-03,\n",
       "        4.46712502e-04, 1.47414871e-03, 5.83249205e-03, 9.64764233e-03,\n",
       "        2.02986329e-02, 5.97557148e-04, 7.18351949e-04, 1.46607780e-03,\n",
       "        7.97659471e-03, 1.28932312e-03, 6.41704789e-04, 1.04851346e-03,\n",
       "        2.09393095e-03, 2.29110016e-03, 6.23345273e-03, 6.80888106e-04,\n",
       "        9.40169758e-04, 1.09826888e-03, 1.20546421e-02, 7.27466371e-03]),\n",
       " 'mean_score_time': array([0.0040524 , 0.00411282, 0.00621357, 0.00941753, 0.01334853,\n",
       "        0.00280638, 0.00355048, 0.00680571, 0.01130733, 0.0130209 ,\n",
       "        0.00254064, 0.00382752, 0.00537858, 0.00945125, 0.01331987,\n",
       "        0.00316834, 0.00394468, 0.00615921, 0.00866451, 0.01359816,\n",
       "        0.00243192, 0.00340476, 0.00675273, 0.00984111, 0.01293998,\n",
       "        0.00391178, 0.00402303, 0.00597229, 0.01048889, 0.01477547,\n",
       "        0.00371385, 0.00404615, 0.00574884, 0.00987191, 0.01394548,\n",
       "        0.00295606, 0.00380907, 0.00611038, 0.01009612, 0.01829057,\n",
       "        0.00340037, 0.00362182, 0.00592556, 0.00874672, 0.01481643,\n",
       "        0.00341949, 0.00339441, 0.00503683, 0.00941133, 0.01500449,\n",
       "        0.00270796, 0.00362678, 0.00532327, 0.00831003, 0.01241937,\n",
       "        0.00254264, 0.00320959, 0.00599704, 0.00999956, 0.01456528,\n",
       "        0.00299659, 0.04163418, 0.00680537, 0.01339622, 0.0156805 ,\n",
       "        0.00418043, 0.00663753, 0.00568132, 0.01062722, 0.01388125,\n",
       "        0.00314846, 0.00416994, 0.00584078, 0.01070046, 0.01365757,\n",
       "        0.00281544, 0.00414257, 0.00994687, 0.01183953, 0.01415453,\n",
       "        0.00321498, 0.00343995, 0.00556302, 0.00939794, 0.0134563 ,\n",
       "        0.00282326, 0.00340967, 0.00666618, 0.01565614, 0.014639  ,\n",
       "        0.00269055, 0.00380378, 0.00670447, 0.01109443, 0.01488752,\n",
       "        0.00331602, 0.0040164 , 0.00656066, 0.00979233, 0.01344371,\n",
       "        0.00253892, 0.00400157, 0.00556049, 0.00979981, 0.01514316,\n",
       "        0.00260143, 0.00338025, 0.00670018, 0.01020427, 0.01415138,\n",
       "        0.00310493, 0.00367055, 0.00621204, 0.01018887, 0.01460204,\n",
       "        0.00314994, 0.00371819, 0.00671787, 0.01043863, 0.0137259 ,\n",
       "        0.00331535, 0.00414653, 0.00621076, 0.00894146, 0.01332903,\n",
       "        0.00259452, 0.00321212, 0.00727086, 0.00996742, 0.01376824,\n",
       "        0.00276971, 0.00393844, 0.00582514, 0.01052814, 0.01399984,\n",
       "        0.00299568, 0.00351491, 0.0055656 , 0.00924277, 0.01316724,\n",
       "        0.00279908, 0.00363121, 0.00614462, 0.009688  , 0.01350818,\n",
       "        0.00279255, 0.00339613, 0.00663457, 0.01147499, 0.01323724,\n",
       "        0.0033752 , 0.00401907, 0.00712223, 0.01088357, 0.01456604,\n",
       "        0.00272841, 0.00394258, 0.00640583, 0.01020699, 0.01314511,\n",
       "        0.00259013, 0.00392871, 0.00584402, 0.01009979, 0.01383457,\n",
       "        0.00280681, 0.00355501, 0.00644188, 0.01001034, 0.01426315,\n",
       "        0.00263419, 0.00376148, 0.00642104, 0.01026936, 0.01355019,\n",
       "        0.00313158, 0.00380669, 0.00580344, 0.00925312, 0.01409292,\n",
       "        0.00236969, 0.00360985, 0.0058867 , 0.00952301, 0.01322441,\n",
       "        0.00284534, 0.00386481, 0.00610538, 0.00981016, 0.0132215 ,\n",
       "        0.00261645, 0.0039742 , 0.0063026 , 0.00929775, 0.01286964,\n",
       "        0.00291185, 0.0033917 , 0.00605783, 0.01256609, 0.01341133,\n",
       "        0.00280232, 0.00368614, 0.00581384, 0.00940838, 0.01339803,\n",
       "        0.00216322, 0.00384793, 0.00559874, 0.00980473, 0.01487627,\n",
       "        0.00314612, 0.00395503, 0.00660224, 0.01083221, 0.01362052,\n",
       "        0.00294938, 0.00489998, 0.0062964 , 0.00971594, 0.01446753,\n",
       "        0.00293117, 0.00340161, 0.00645466, 0.01078258, 0.01657796,\n",
       "        0.0034152 , 0.00395899, 0.0074038 , 0.00988746, 0.01402178,\n",
       "        0.00279837, 0.00359583, 0.0056592 , 0.00985427, 0.01547804,\n",
       "        0.00299759, 0.00386314, 0.00630355, 0.01074471, 0.01564574,\n",
       "        0.00300035, 0.00342317, 0.00660806, 0.01019011, 0.01579814,\n",
       "        0.00381413, 0.00442324, 0.00637541, 0.01092653, 0.01670017,\n",
       "        0.00308967, 0.00444808, 0.00751357, 0.01059184, 0.01479774,\n",
       "        0.00242543, 0.00413771, 0.00651131, 0.01014233, 0.01417742,\n",
       "        0.00260043, 0.00396185, 0.00640674, 0.0100512 , 0.01386728,\n",
       "        0.0027545 , 0.00323234, 0.00560036, 0.00913091, 0.01325994,\n",
       "        0.00303288, 0.00368209, 0.00643573, 0.01014705, 0.01387453,\n",
       "        0.00279632, 0.00358095, 0.00696282, 0.0101615 , 0.01364727,\n",
       "        0.00278897, 0.00340452, 0.00614257, 0.00985017, 0.01342092,\n",
       "        0.00436001, 0.00395188, 0.00518103, 0.01027465, 0.01671414,\n",
       "        0.00300932, 0.00340648, 0.00560641, 0.01032782, 0.0133812 ,\n",
       "        0.00282316, 0.00424066, 0.0067287 , 0.01045566, 0.01415787,\n",
       "        0.00325446, 0.00340743, 0.00662789, 0.0102747 , 0.01400952,\n",
       "        0.00300527, 0.00400691, 0.00559936, 0.01018434, 0.01309595,\n",
       "        0.00241256, 0.00341959, 0.00602636, 0.00924864, 0.01315231,\n",
       "        0.00279236, 0.00299587, 0.00583291, 0.00952587, 0.01596713,\n",
       "        0.00259776, 0.00340123, 0.00560017, 0.01008468, 0.01645198,\n",
       "        0.00339279, 0.00331182, 0.00697479, 0.01070876, 0.01397643,\n",
       "        0.00320067, 0.00345712, 0.00705981, 0.01081505, 0.01394806,\n",
       "        0.00248613, 0.00450168, 0.00598645, 0.00965719, 0.01492128,\n",
       "        0.00320573, 0.00359206, 0.00585041, 0.00968857, 0.01410532,\n",
       "        0.00282154, 0.0039453 , 0.00564241, 0.00952802, 0.01478701,\n",
       "        0.0026638 , 0.00348997, 0.00671134, 0.0106266 , 0.01581993,\n",
       "        0.00224152, 0.00407786, 0.0055397 , 0.01054678, 0.01323252,\n",
       "        0.00260949, 0.00330505, 0.00641952, 0.01049237, 0.01566191,\n",
       "        0.00260534, 0.00408735, 0.00590119, 0.00985188, 0.01343203,\n",
       "        0.0028481 , 0.00325398, 0.00685711, 0.00971808, 0.01432633,\n",
       "        0.00249567, 0.0040029 , 0.00587931, 0.01135254, 0.01380668,\n",
       "        0.00279531, 0.00380425, 0.0065032 , 0.00931396, 0.01343694,\n",
       "        0.00300384, 0.00380015, 0.00597496, 0.01001472, 0.01458926,\n",
       "        0.00280743, 0.00360169, 0.00703611, 0.00993733, 0.01511893,\n",
       "        0.00300817, 0.00479074, 0.00586238, 0.01004806, 0.01499805,\n",
       "        0.00340071, 0.00355182, 0.00692363, 0.01017346, 0.01439447,\n",
       "        0.00258212, 0.0036767 , 0.00613313, 0.00979085, 0.01409216,\n",
       "        0.00278096, 0.00341153, 0.00819082, 0.01090817, 0.01430964,\n",
       "        0.00289769, 0.00386744, 0.00657344, 0.01114883, 0.01381407,\n",
       "        0.00266199, 0.00358682, 0.00605512, 0.00984645, 0.01344647,\n",
       "        0.0031117 , 0.00428009, 0.00723891, 0.01121092, 0.01406994,\n",
       "        0.00304976, 0.00402145, 0.00733223, 0.01052766, 0.01382899,\n",
       "        0.00278864, 0.00361414, 0.00579953, 0.00944986, 0.01442475,\n",
       "        0.0026082 , 0.00361638, 0.00624866, 0.00982461, 0.01316838,\n",
       "        0.00283647, 0.00360017, 0.00602412, 0.00949483, 0.01359816,\n",
       "        0.00281658, 0.0037755 , 0.00638232, 0.01064844, 0.0142695 ,\n",
       "        0.00241117, 0.00320477, 0.00579853, 0.00994201, 0.01382928,\n",
       "        0.00256104, 0.00324297, 0.00624585, 0.00921922, 0.01351113,\n",
       "        0.00239954, 0.00394621, 0.0058279 , 0.00982757, 0.01330438,\n",
       "        0.00319643, 0.00330911, 0.00580316, 0.01106782, 0.01368928,\n",
       "        0.00288415, 0.00451646, 0.00644073, 0.01082759, 0.01327138,\n",
       "        0.00260186, 0.0038146 , 0.0063077 , 0.01097789, 0.01540408,\n",
       "        0.0030026 , 0.00369158, 0.00671358, 0.01052976, 0.01384048,\n",
       "        0.00281129, 0.00419512, 0.0066052 , 0.00994458, 0.01487103,\n",
       "        0.00309396, 0.00374179, 0.00610905, 0.0102519 , 0.01418633,\n",
       "        0.00299873, 0.00400066, 0.00770392, 0.01044126, 0.01431036,\n",
       "        0.00325351, 0.00414476, 0.00639305, 0.01162262, 0.01767592,\n",
       "        0.00281019, 0.00342169, 0.00605669, 0.00987353, 0.01428423,\n",
       "        0.00279784, 0.00320539, 0.00576348, 0.01070976, 0.01457472,\n",
       "        0.00240455, 0.0034524 , 0.00564137, 0.00911903, 0.01287827,\n",
       "        0.00240073, 0.00340309, 0.00684972, 0.01035771, 0.01472216,\n",
       "        0.00350823, 0.00400071, 0.00670376, 0.01013255, 0.01478801,\n",
       "        0.00231371, 0.00412903, 0.00581779, 0.01031213, 0.01343269,\n",
       "        0.00244794, 0.00299544, 0.00568657, 0.01038332, 0.01385598,\n",
       "        0.00304642, 0.00355458, 0.00525684, 0.00946631, 0.01322308,\n",
       "        0.00280929, 0.00360565, 0.00834532, 0.01076941, 0.01307435,\n",
       "        0.00253358, 0.00428925, 0.00640149, 0.01092291, 0.01450996,\n",
       "        0.0032568 , 0.00458841, 0.00648322, 0.01063833, 0.01385169,\n",
       "        0.0032105 , 0.003795  , 0.00600257, 0.01049671, 0.01407304,\n",
       "        0.00276327, 0.00382867, 0.00638909, 0.01077518, 0.01462412,\n",
       "        0.00297012, 0.00391994, 0.00612125, 0.01071482, 0.01435351,\n",
       "        0.00355644, 0.00407357, 0.00585265, 0.0103128 , 0.01424384,\n",
       "        0.00317636, 0.0038064 , 0.00634041, 0.01027331, 0.01387839,\n",
       "        0.00263906, 0.00377603, 0.00684338, 0.01017523, 0.01345201,\n",
       "        0.00239344, 0.00364456, 0.00573392, 0.01143365, 0.01289358,\n",
       "        0.00262213, 0.00359802, 0.00546017, 0.01072774, 0.01323824,\n",
       "        0.00280857, 0.00418444, 0.00581541, 0.01013918, 0.01274104,\n",
       "        0.00322447, 0.0039649 , 0.00582027, 0.00971441, 0.01358595,\n",
       "        0.00287333, 0.00408969, 0.00559325, 0.00898042, 0.01409593,\n",
       "        0.0028553 , 0.00303364, 0.0081358 , 0.00989747, 0.01399608,\n",
       "        0.00294757, 0.00339732, 0.00573435, 0.00920134, 0.01320615,\n",
       "        0.00240932, 0.00360312, 0.00559735, 0.00980248, 0.01367927,\n",
       "        0.00283165, 0.00359254, 0.00578232, 0.00946774, 0.01457777]),\n",
       " 'std_score_time': array([9.92465269e-05, 2.28577481e-04, 1.49056328e-03, 7.26646261e-04,\n",
       "        4.71789186e-04, 4.03006687e-04, 4.56541770e-04, 1.18606191e-03,\n",
       "        8.53763324e-04, 4.51255408e-04, 4.16247142e-04, 4.84596079e-04,\n",
       "        4.52604266e-04, 3.39127164e-04, 1.51868560e-03, 3.22609218e-04,\n",
       "        2.90444930e-04, 7.94645363e-04, 4.36238185e-04, 7.95933699e-04,\n",
       "        5.25803783e-04, 4.85730742e-04, 2.06451301e-03, 1.85275601e-03,\n",
       "        2.54478543e-04, 1.00300617e-03, 6.63296571e-04, 1.45644609e-03,\n",
       "        3.89352843e-04, 1.44506689e-03, 1.96524563e-03, 1.14786051e-03,\n",
       "        4.38751330e-04, 4.31436543e-04, 4.41052065e-04, 5.64762307e-04,\n",
       "        4.02403598e-04, 1.18790357e-03, 5.35434995e-04, 7.82315220e-03,\n",
       "        3.81108065e-04, 4.43479450e-04, 8.62349258e-04, 6.58074143e-04,\n",
       "        1.49061189e-03, 4.86253289e-04, 4.86386159e-04, 7.93234056e-05,\n",
       "        1.02197461e-03, 2.36243603e-03, 6.08676945e-04, 6.05828363e-04,\n",
       "        4.02353250e-04, 4.11261680e-04, 8.03494278e-04, 4.46910411e-04,\n",
       "        3.90296006e-04, 9.06066573e-04, 1.58648680e-03, 9.76269315e-04,\n",
       "        5.63476830e-04, 5.46323428e-02, 4.50445008e-04, 3.07024366e-03,\n",
       "        3.57504210e-03, 1.05954581e-03, 2.06407030e-03, 3.94735160e-04,\n",
       "        1.08049583e-03, 3.80972043e-04, 4.17269149e-04, 8.80383543e-04,\n",
       "        4.35313440e-04, 1.14027293e-03, 1.88746357e-03, 7.74280322e-04,\n",
       "        7.68544313e-04, 5.55998158e-03, 3.07601940e-03, 1.52036262e-03,\n",
       "        3.93291334e-04, 3.92891318e-04, 7.31459450e-04, 7.90627031e-04,\n",
       "        5.86327517e-04, 4.12633470e-04, 4.92975863e-04, 3.58388918e-04,\n",
       "        8.39409052e-03, 5.77934005e-04, 5.90572340e-04, 4.04370123e-04,\n",
       "        9.10484944e-04, 8.65815757e-04, 1.14635877e-03, 3.97406472e-04,\n",
       "        3.66759014e-04, 1.23056172e-03, 7.25378894e-04, 4.00912903e-04,\n",
       "        4.53836488e-04, 9.05649578e-04, 4.88582454e-04, 6.14721195e-04,\n",
       "        1.43840256e-03, 4.89143229e-04, 4.85294406e-04, 1.33084831e-03,\n",
       "        4.78286767e-04, 4.69607754e-04, 2.46485978e-04, 8.19955673e-04,\n",
       "        7.42734933e-04, 4.24482474e-04, 1.87469224e-03, 6.96677633e-04,\n",
       "        3.97379718e-04, 4.41020380e-04, 1.21678711e-03, 9.12290449e-04,\n",
       "        8.99560833e-04, 1.51932249e-03, 1.38169324e-03, 4.96736545e-04,\n",
       "        6.27866064e-04, 4.82862395e-04, 4.08238797e-04, 2.09784215e-03,\n",
       "        6.38410337e-04, 6.77357185e-04, 4.30141345e-04, 3.10042146e-04,\n",
       "        4.11309699e-04, 1.02570330e-03, 1.71981865e-03, 1.98883971e-05,\n",
       "        4.22862531e-04, 7.53526517e-04, 3.84100663e-04, 3.72468691e-04,\n",
       "        4.04258887e-04, 4.26695050e-04, 1.33897112e-03, 9.73389166e-04,\n",
       "        8.11706123e-04, 3.95204794e-04, 4.80581522e-04, 1.00784847e-03,\n",
       "        1.30223331e-03, 1.78811582e-04, 4.33832112e-04, 8.24507614e-04,\n",
       "        6.93156503e-04, 9.97846384e-04, 4.40045125e-04, 5.94865495e-04,\n",
       "        5.30431854e-04, 1.02448260e-03, 5.49895206e-04, 4.77426108e-04,\n",
       "        4.81477815e-04, 8.66313733e-04, 4.26932591e-04, 1.27112445e-04,\n",
       "        8.55079326e-04, 3.98184684e-04, 4.38564931e-04, 6.44239726e-04,\n",
       "        1.11016498e-03, 5.08357479e-04, 4.26644238e-04, 6.75710850e-04,\n",
       "        8.71278121e-04, 6.15896179e-04, 9.43951427e-04, 6.79874838e-04,\n",
       "        7.51110943e-04, 7.46851466e-04, 5.44434296e-04, 2.15642083e-03,\n",
       "        4.35196069e-04, 4.78218210e-04, 5.36902603e-04, 6.54755668e-04,\n",
       "        3.56054130e-04, 4.35944298e-04, 4.51742986e-04, 1.28167087e-04,\n",
       "        7.08410880e-04, 1.06267000e-03, 5.04757356e-04, 1.08533320e-03,\n",
       "        7.38184950e-04, 3.61540204e-04, 4.44636176e-04, 6.68432318e-04,\n",
       "        4.90723853e-04, 1.17306781e-03, 3.69230233e-03, 5.01588753e-04,\n",
       "        4.02330866e-04, 4.26007139e-04, 4.07546557e-04, 5.07271812e-04,\n",
       "        5.74148029e-04, 3.01089625e-04, 7.05536413e-04, 4.92913063e-04,\n",
       "        3.93613261e-04, 2.77576597e-03, 2.07236161e-04, 5.04113759e-04,\n",
       "        1.19917163e-03, 1.14655255e-03, 4.63469592e-04, 1.08565737e-04,\n",
       "        1.84347104e-03, 5.77233291e-04, 8.98543287e-04, 1.29997336e-03,\n",
       "        9.51800174e-05, 4.76332292e-04, 8.31724864e-04, 1.47324501e-03,\n",
       "        1.45864127e-03, 9.68803769e-04, 5.23877668e-04, 2.07405519e-03,\n",
       "        9.21295838e-04, 1.96928030e-03, 3.99023232e-04, 4.86547402e-04,\n",
       "        5.92801236e-04, 3.32037618e-04, 2.41924581e-03, 8.61136752e-06,\n",
       "        6.31704635e-04, 7.05841270e-04, 1.13063390e-03, 1.64761523e-03,\n",
       "        8.94682288e-04, 5.24244483e-04, 1.34785100e-03, 6.80144526e-04,\n",
       "        2.57570338e-03, 1.16848835e-03, 9.66433663e-04, 4.80759004e-04,\n",
       "        7.82016827e-04, 5.74542177e-03, 2.78021090e-04, 8.96144045e-04,\n",
       "        1.70620920e-03, 6.45188086e-04, 1.07456575e-03, 5.29631878e-04,\n",
       "        1.08053070e-03, 1.30076077e-03, 6.14662425e-04, 7.63096802e-04,\n",
       "        4.84560386e-04, 6.44035662e-04, 1.03341216e-03, 6.31104335e-04,\n",
       "        8.12536081e-04, 4.13229937e-04, 3.86040060e-04, 7.99489866e-04,\n",
       "        4.39838208e-04, 6.83864874e-04, 7.44909691e-05, 5.56012684e-04,\n",
       "        1.03697440e-03, 9.18785848e-04, 4.43856640e-04, 4.02066920e-04,\n",
       "        4.99376433e-04, 1.65607839e-03, 3.06997843e-04, 1.30829964e-03,\n",
       "        3.98304547e-04, 4.94454557e-04, 2.01447723e-04, 6.84517580e-04,\n",
       "        8.42290029e-04, 1.74219567e-03, 8.87120388e-05, 3.92593252e-04,\n",
       "        1.55621388e-03, 4.01047327e-03, 6.34150557e-04, 4.91324858e-04,\n",
       "        4.91606646e-04, 4.15907254e-04, 4.86958363e-04, 3.38829808e-04,\n",
       "        4.41663055e-04, 4.23558142e-04, 8.83849880e-04, 1.00485826e-03,\n",
       "        3.93789765e-04, 5.10332223e-04, 1.65967227e-03, 1.15201663e-03,\n",
       "        9.62307967e-04, 1.10673180e-03, 9.25805964e-04, 4.91444083e-04,\n",
       "        2.55048798e-04, 6.57893501e-04, 4.85391185e-04, 5.15843650e-04,\n",
       "        6.22649510e-04, 3.83381422e-04, 3.14982017e-04, 3.96406749e-04,\n",
       "        1.75561573e-05, 4.19707641e-04, 6.79351467e-04, 3.68038873e-03,\n",
       "        4.88102552e-04, 4.91583783e-04, 4.89459288e-04, 1.04725360e-04,\n",
       "        3.42836941e-03, 4.43027646e-04, 4.17993979e-04, 8.54537688e-05,\n",
       "        7.07030775e-04, 6.72598377e-05, 7.48353781e-04, 5.67089933e-04,\n",
       "        1.52691540e-03, 7.64055101e-04, 5.24211242e-04, 4.50869229e-04,\n",
       "        1.59083366e-03, 6.22203977e-04, 5.70937072e-04, 1.96654736e-03,\n",
       "        3.95981390e-04, 5.01729961e-04, 4.28435801e-04, 5.74604869e-04,\n",
       "        8.35016137e-04, 7.56926153e-04, 7.04833574e-04, 5.23493107e-04,\n",
       "        5.21838321e-04, 8.89674528e-04, 5.53939808e-04, 6.13671027e-04,\n",
       "        9.62221617e-04, 1.00947565e-03, 1.20665115e-03, 3.82649344e-04,\n",
       "        1.25900669e-04, 4.52973149e-04, 1.09601511e-03, 3.56113004e-04,\n",
       "        5.01006337e-04, 6.19620753e-04, 4.62427806e-04, 1.09739164e-03,\n",
       "        2.63879320e-03, 4.94349172e-04, 1.42469064e-04, 8.34085059e-04,\n",
       "        2.93438838e-04, 5.34719351e-04, 3.26324491e-04, 5.09230081e-04,\n",
       "        5.67849081e-04, 3.96589412e-04, 2.26749174e-03, 6.25383806e-04,\n",
       "        6.13736319e-04, 8.67425648e-04, 3.19684003e-03, 4.06259791e-04,\n",
       "        3.98708997e-04, 4.02397773e-04, 4.89868104e-04, 4.12597155e-04,\n",
       "        8.67201069e-04, 3.68027478e-05, 4.00185596e-04, 5.95046070e-04,\n",
       "        9.29872236e-04, 2.25269635e-03, 4.04206998e-04, 4.86997985e-04,\n",
       "        3.09231499e-03, 1.21552822e-03, 1.02754603e-03, 2.30324688e-05,\n",
       "        1.06682494e-03, 4.53781339e-04, 6.39821311e-04, 1.76740607e-03,\n",
       "        1.35784893e-03, 7.30498537e-04, 1.44433410e-03, 1.12435249e-03,\n",
       "        9.53121805e-04, 4.76556180e-04, 5.72347691e-04, 6.90367357e-04,\n",
       "        5.50705826e-04, 1.08001501e-04, 3.91005318e-04, 7.99964207e-04,\n",
       "        2.87649033e-03, 7.90911906e-04, 1.08976501e-03, 2.14238770e-04,\n",
       "        4.48648158e-04, 5.26263463e-04, 3.22371562e-03, 6.98621386e-04,\n",
       "        3.65369962e-04, 4.79664204e-04, 7.32014153e-05, 2.36798840e-04,\n",
       "        5.45460309e-04, 1.25902740e-03, 4.94857298e-04, 2.78558911e-03,\n",
       "        7.89597917e-04, 3.19896776e-04, 6.16070704e-04, 1.72766466e-05,\n",
       "        1.28583127e-03, 6.58371594e-04, 9.83692047e-04, 3.94999123e-04,\n",
       "        4.83545076e-04, 3.98892310e-04, 5.79597215e-04, 1.22923048e-03,\n",
       "        5.06534433e-04, 4.99144277e-04, 9.42953738e-04, 6.02565452e-04,\n",
       "        1.48006321e-04, 8.16442512e-04, 4.90212843e-04, 5.28880984e-05,\n",
       "        4.44425979e-04, 1.04798035e-03, 3.83043043e-04, 6.25907080e-04,\n",
       "        5.01214731e-04, 1.25003533e-03, 7.94461888e-04, 4.97296200e-04,\n",
       "        4.08217097e-04, 3.96180387e-04, 9.91025631e-04, 9.82736863e-04,\n",
       "        4.83198115e-04, 3.82071527e-04, 3.02149889e-04, 7.74758529e-04,\n",
       "        9.82569628e-04, 4.90114507e-04, 5.44943924e-04, 3.36198941e-04,\n",
       "        6.89412697e-04, 1.07392882e-03, 3.97500030e-04, 3.87610998e-04,\n",
       "        4.02009850e-04, 1.66830693e-03, 1.30863297e-03, 4.70791423e-04,\n",
       "        4.44974426e-04, 6.30045238e-04, 1.07643455e-03, 7.34629065e-04,\n",
       "        5.05170004e-04, 4.05959134e-04, 3.63994718e-04, 9.03396829e-04,\n",
       "        4.15242671e-04, 1.09928580e-03, 5.31806493e-04, 1.26256873e-03,\n",
       "        4.57962658e-04, 1.21660273e-03, 4.06611758e-04, 3.89648020e-04,\n",
       "        4.94913566e-04, 6.50253072e-04, 2.98220631e-03, 1.90267049e-04,\n",
       "        3.64422916e-04, 1.40963694e-04, 1.38183971e-03, 9.43408422e-04,\n",
       "        1.07268226e-05, 7.49995276e-05, 3.12642624e-03, 8.11099998e-04,\n",
       "        2.09698920e-03, 3.83163073e-04, 8.81379547e-04, 5.34630166e-04,\n",
       "        3.24333994e-03, 4.53093171e-03, 4.06349295e-04, 8.22835077e-04,\n",
       "        2.91874381e-04, 1.02187044e-03, 1.67043775e-03, 3.98881850e-04,\n",
       "        3.83691416e-04, 6.63231694e-04, 1.39161850e-03, 1.78370247e-03,\n",
       "        4.84852857e-04, 5.53033541e-04, 5.30920449e-04, 1.03437949e-04,\n",
       "        7.98760990e-04, 4.89512945e-04, 4.94075244e-04, 1.63549273e-03,\n",
       "        4.86003524e-04, 3.67001380e-04, 1.08660508e-03, 6.45150814e-04,\n",
       "        2.00739156e-03, 5.59593730e-04, 2.26289990e-03, 5.78204224e-04,\n",
       "        7.16159228e-04, 4.12605256e-04, 1.29442101e-03, 5.57118003e-04,\n",
       "        5.40328644e-04, 2.79047126e-05, 8.54706636e-04, 9.10515346e-04,\n",
       "        1.19711563e-03, 9.35097728e-05, 4.48383142e-04, 3.69611716e-04,\n",
       "        4.17181491e-04, 7.81609888e-04, 3.99386291e-04, 4.80587549e-04,\n",
       "        4.98586929e-03, 6.58910943e-04, 1.42561823e-04, 4.55025380e-04,\n",
       "        5.90627366e-04, 5.28990739e-04, 1.27532552e-03, 1.18970349e-03,\n",
       "        4.57517066e-04, 1.73817514e-03, 1.51791649e-03, 8.20307907e-04,\n",
       "        4.05064827e-04, 3.95566541e-04, 3.97429672e-04, 4.95222421e-06,\n",
       "        6.11351424e-04, 1.14780344e-03, 7.54997476e-04, 7.74780689e-04,\n",
       "        5.53741804e-04, 2.22892706e-03, 1.38209616e-03, 6.57815136e-05,\n",
       "        7.71628530e-04, 3.38870747e-04, 1.70412460e-03, 7.45738375e-04,\n",
       "        6.89815407e-04, 7.31741383e-05, 7.66427566e-04, 1.20116310e-03,\n",
       "        8.07167865e-04, 3.42693832e-04, 4.06561450e-04, 9.08580249e-04,\n",
       "        1.58779248e-03, 7.00346359e-04, 8.64076034e-04, 7.65265932e-04,\n",
       "        7.62481528e-04, 8.50524014e-04, 6.61571087e-04, 4.95511991e-04,\n",
       "        5.65484252e-04, 6.35781923e-04, 1.67880806e-03, 8.19700670e-04,\n",
       "        5.21720716e-04, 4.86731991e-04, 9.14164495e-04, 1.14395620e-03,\n",
       "        5.06824973e-04, 7.33115366e-04, 9.51177696e-04, 4.10895717e-04,\n",
       "        4.54230517e-04, 5.42283452e-04, 1.04614615e-03, 5.49811171e-04,\n",
       "        6.21998131e-04, 5.04449755e-04, 8.19045832e-04, 3.46905590e-04,\n",
       "        6.60132019e-04, 7.94029479e-04, 1.39352149e-04, 9.62062432e-04,\n",
       "        7.64585626e-04, 3.93085650e-05, 1.54735794e-03, 8.54182586e-04,\n",
       "        1.85768768e-03, 5.53032644e-04, 4.88162762e-04, 7.37248779e-04,\n",
       "        7.49210367e-04, 3.05268773e-04, 5.06746463e-04, 4.86070421e-04,\n",
       "        4.88430402e-04, 7.32484203e-04, 1.66316946e-03, 4.21248277e-04,\n",
       "        4.08568908e-04, 3.90646012e-04, 7.48810088e-04, 9.20973224e-04]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.64583333, 0.59375   , 0.63541667, 0.64583333, 0.63541667,\n",
       "        0.70833333, 0.6875    , 0.63541667, 0.625     , 0.63541667,\n",
       "        0.6875    , 0.60416667, 0.60416667, 0.63541667, 0.63541667,\n",
       "        0.64583333, 0.59375   , 0.65625   , 0.65625   , 0.625     ,\n",
       "        0.59375   , 0.58333333, 0.66666667, 0.63541667, 0.64583333,\n",
       "        0.75      , 0.61458333, 0.63541667, 0.66666667, 0.60416667,\n",
       "        0.625     , 0.67708333, 0.66666667, 0.60416667, 0.65625   ,\n",
       "        0.66666667, 0.64583333, 0.64583333, 0.65625   , 0.63541667,\n",
       "        0.64583333, 0.61458333, 0.67708333, 0.65625   , 0.66666667,\n",
       "        0.60416667, 0.60416667, 0.60416667, 0.64583333, 0.625     ,\n",
       "        0.57291667, 0.6875    , 0.60416667, 0.60416667, 0.63541667,\n",
       "        0.65625   , 0.65625   , 0.64583333, 0.64583333, 0.64583333,\n",
       "        0.60416667, 0.70833333, 0.64583333, 0.6875    , 0.625     ,\n",
       "        0.69791667, 0.70833333, 0.60416667, 0.63541667, 0.65625   ,\n",
       "        0.5625    , 0.70833333, 0.61458333, 0.625     , 0.63541667,\n",
       "        0.66666667, 0.65625   , 0.64583333, 0.64583333, 0.60416667,\n",
       "        0.61458333, 0.625     , 0.65625   , 0.61458333, 0.61458333,\n",
       "        0.65625   , 0.66666667, 0.63541667, 0.625     , 0.64583333,\n",
       "        0.6875    , 0.60416667, 0.64583333, 0.6875    , 0.65625   ,\n",
       "        0.65625   , 0.71875   , 0.63541667, 0.6875    , 0.64583333,\n",
       "        0.66666667, 0.67708333, 0.61458333, 0.65625   , 0.625     ,\n",
       "        0.67708333, 0.67708333, 0.63541667, 0.64583333, 0.69791667,\n",
       "        0.66666667, 0.64583333, 0.69791667, 0.625     , 0.66666667,\n",
       "        0.63541667, 0.625     , 0.67708333, 0.66666667, 0.625     ,\n",
       "        0.64583333, 0.58333333, 0.625     , 0.64583333, 0.60416667,\n",
       "        0.71875   , 0.57291667, 0.64583333, 0.625     , 0.625     ,\n",
       "        0.63541667, 0.58333333, 0.70833333, 0.66666667, 0.63541667,\n",
       "        0.73958333, 0.6875    , 0.60416667, 0.65625   , 0.625     ,\n",
       "        0.63541667, 0.65625   , 0.61458333, 0.59375   , 0.60416667,\n",
       "        0.61458333, 0.70833333, 0.60416667, 0.64583333, 0.61458333,\n",
       "        0.71875   , 0.60416667, 0.60416667, 0.625     , 0.625     ,\n",
       "        0.60416667, 0.59375   , 0.61458333, 0.60416667, 0.63541667,\n",
       "        0.60416667, 0.67708333, 0.63541667, 0.625     , 0.59375   ,\n",
       "        0.58333333, 0.65625   , 0.61458333, 0.66666667, 0.64583333,\n",
       "        0.625     , 0.65625   , 0.66666667, 0.625     , 0.63541667,\n",
       "        0.64583333, 0.63541667, 0.64583333, 0.61458333, 0.65625   ,\n",
       "        0.65625   , 0.66666667, 0.61458333, 0.625     , 0.63541667,\n",
       "        0.61458333, 0.65625   , 0.63541667, 0.64583333, 0.63541667,\n",
       "        0.66666667, 0.63541667, 0.625     , 0.61458333, 0.625     ,\n",
       "        0.63541667, 0.65625   , 0.59375   , 0.64583333, 0.66666667,\n",
       "        0.54166667, 0.71875   , 0.625     , 0.64583333, 0.625     ,\n",
       "        0.71875   , 0.60416667, 0.61458333, 0.61458333, 0.64583333,\n",
       "        0.64583333, 0.65625   , 0.65625   , 0.64583333, 0.60416667,\n",
       "        0.625     , 0.625     , 0.61458333, 0.64583333, 0.63541667,\n",
       "        0.73958333, 0.61458333, 0.625     , 0.625     , 0.66666667,\n",
       "        0.65625   , 0.69791667, 0.66666667, 0.625     , 0.61458333,\n",
       "        0.60416667, 0.66666667, 0.61458333, 0.61458333, 0.61458333,\n",
       "        0.55208333, 0.64583333, 0.59375   , 0.60416667, 0.66666667,\n",
       "        0.59375   , 0.625     , 0.64583333, 0.63541667, 0.64583333,\n",
       "        0.61458333, 0.69791667, 0.63541667, 0.64583333, 0.63541667,\n",
       "        0.59375   , 0.69791667, 0.61458333, 0.65625   , 0.65625   ,\n",
       "        0.61458333, 0.63541667, 0.64583333, 0.63541667, 0.64583333,\n",
       "        0.61458333, 0.61458333, 0.65625   , 0.65625   , 0.63541667,\n",
       "        0.65625   , 0.625     , 0.69791667, 0.63541667, 0.67708333,\n",
       "        0.71875   , 0.69791667, 0.65625   , 0.6875    , 0.65625   ,\n",
       "        0.625     , 0.69791667, 0.64583333, 0.63541667, 0.65625   ,\n",
       "        0.625     , 0.64583333, 0.66666667, 0.67708333, 0.625     ,\n",
       "        0.625     , 0.64583333, 0.65625   , 0.59375   , 0.66666667,\n",
       "        0.5625    , 0.65625   , 0.59375   , 0.625     , 0.66666667,\n",
       "        0.55208333, 0.61458333, 0.65625   , 0.6875    , 0.63541667,\n",
       "        0.65625   , 0.67708333, 0.64583333, 0.59375   , 0.65625   ,\n",
       "        0.70833333, 0.61458333, 0.625     , 0.66666667, 0.60416667,\n",
       "        0.58333333, 0.66666667, 0.67708333, 0.61458333, 0.61458333,\n",
       "        0.65625   , 0.625     , 0.66666667, 0.625     , 0.61458333,\n",
       "        0.59375   , 0.64583333, 0.67708333, 0.67708333, 0.61458333,\n",
       "        0.625     , 0.625     , 0.59375   , 0.64583333, 0.66666667,\n",
       "        0.66666667, 0.67708333, 0.61458333, 0.66666667, 0.67708333,\n",
       "        0.6875    , 0.6875    , 0.65625   , 0.66666667, 0.70833333,\n",
       "        0.6875    , 0.65625   , 0.6875    , 0.65625   , 0.625     ,\n",
       "        0.60416667, 0.61458333, 0.625     , 0.64583333, 0.63541667,\n",
       "        0.6875    , 0.63541667, 0.61458333, 0.63541667, 0.65625   ,\n",
       "        0.65625   , 0.64583333, 0.64583333, 0.66666667, 0.66666667,\n",
       "        0.66666667, 0.64583333, 0.64583333, 0.65625   , 0.625     ,\n",
       "        0.63541667, 0.61458333, 0.66666667, 0.66666667, 0.66666667,\n",
       "        0.65625   , 0.66666667, 0.64583333, 0.625     , 0.66666667,\n",
       "        0.61458333, 0.66666667, 0.61458333, 0.59375   , 0.61458333,\n",
       "        0.66666667, 0.6875    , 0.67708333, 0.61458333, 0.60416667,\n",
       "        0.6875    , 0.65625   , 0.59375   , 0.63541667, 0.66666667,\n",
       "        0.70833333, 0.60416667, 0.6875    , 0.625     , 0.625     ,\n",
       "        0.65625   , 0.65625   , 0.61458333, 0.64583333, 0.61458333,\n",
       "        0.64583333, 0.61458333, 0.66666667, 0.64583333, 0.63541667,\n",
       "        0.63541667, 0.64583333, 0.64583333, 0.64583333, 0.65625   ,\n",
       "        0.60416667, 0.64583333, 0.61458333, 0.60416667, 0.64583333,\n",
       "        0.65625   , 0.67708333, 0.61458333, 0.66666667, 0.67708333,\n",
       "        0.625     , 0.69791667, 0.66666667, 0.66666667, 0.64583333,\n",
       "        0.65625   , 0.64583333, 0.69791667, 0.66666667, 0.64583333,\n",
       "        0.625     , 0.6875    , 0.67708333, 0.66666667, 0.66666667,\n",
       "        0.64583333, 0.66666667, 0.66666667, 0.66666667, 0.61458333,\n",
       "        0.73958333, 0.72916667, 0.60416667, 0.63541667, 0.63541667,\n",
       "        0.65625   , 0.6875    , 0.64583333, 0.625     , 0.60416667,\n",
       "        0.70833333, 0.63541667, 0.6875    , 0.625     , 0.64583333,\n",
       "        0.59375   , 0.6875    , 0.65625   , 0.625     , 0.69791667,\n",
       "        0.71875   , 0.70833333, 0.66666667, 0.66666667, 0.61458333,\n",
       "        0.64583333, 0.57291667, 0.64583333, 0.625     , 0.63541667,\n",
       "        0.625     , 0.69791667, 0.61458333, 0.61458333, 0.60416667,\n",
       "        0.70833333, 0.64583333, 0.65625   , 0.60416667, 0.65625   ,\n",
       "        0.65625   , 0.61458333, 0.63541667, 0.625     , 0.625     ,\n",
       "        0.64583333, 0.625     , 0.63541667, 0.63541667, 0.6875    ,\n",
       "        0.67708333, 0.59375   , 0.66666667, 0.61458333, 0.65625   ,\n",
       "        0.71875   , 0.61458333, 0.66666667, 0.64583333, 0.67708333,\n",
       "        0.63541667, 0.65625   , 0.66666667, 0.65625   , 0.63541667,\n",
       "        0.64583333, 0.67708333, 0.63541667, 0.64583333, 0.65625   ,\n",
       "        0.67708333, 0.61458333, 0.67708333, 0.66666667, 0.64583333,\n",
       "        0.625     , 0.65625   , 0.67708333, 0.64583333, 0.67708333,\n",
       "        0.67708333, 0.64583333, 0.625     , 0.6875    , 0.63541667,\n",
       "        0.69791667, 0.73958333, 0.67708333, 0.61458333, 0.64583333,\n",
       "        0.6875    , 0.67708333, 0.65625   , 0.6875    , 0.60416667,\n",
       "        0.66666667, 0.60416667, 0.63541667, 0.64583333, 0.65625   ,\n",
       "        0.67708333, 0.59375   , 0.66666667, 0.65625   , 0.61458333,\n",
       "        0.64583333, 0.67708333, 0.63541667, 0.67708333, 0.64583333,\n",
       "        0.69791667, 0.60416667, 0.63541667, 0.66666667, 0.625     ,\n",
       "        0.64583333, 0.66666667, 0.65625   , 0.625     , 0.64583333,\n",
       "        0.63541667, 0.625     , 0.61458333, 0.625     , 0.625     ,\n",
       "        0.59375   , 0.61458333, 0.63541667, 0.63541667, 0.65625   ,\n",
       "        0.60416667, 0.64583333, 0.6875    , 0.65625   , 0.64583333,\n",
       "        0.67708333, 0.61458333, 0.67708333, 0.65625   , 0.69791667,\n",
       "        0.65625   , 0.70833333, 0.64583333, 0.65625   , 0.64583333,\n",
       "        0.71875   , 0.64583333, 0.64583333, 0.65625   , 0.65625   ,\n",
       "        0.64583333, 0.61458333, 0.64583333, 0.64583333, 0.63541667,\n",
       "        0.65625   , 0.67708333, 0.6875    , 0.63541667, 0.66666667,\n",
       "        0.625     , 0.69791667, 0.65625   , 0.65625   , 0.64583333,\n",
       "        0.59375   , 0.69791667, 0.67708333, 0.67708333, 0.61458333,\n",
       "        0.76041667, 0.66666667, 0.6875    , 0.64583333, 0.625     ,\n",
       "        0.67708333, 0.67708333, 0.625     , 0.65625   , 0.65625   ,\n",
       "        0.64583333, 0.65625   , 0.65625   , 0.6875    , 0.64583333,\n",
       "        0.6875    , 0.66666667, 0.65625   , 0.625     , 0.63541667,\n",
       "        0.59375   , 0.69791667, 0.69791667, 0.60416667, 0.58333333,\n",
       "        0.69791667, 0.64583333, 0.61458333, 0.65625   , 0.61458333]),\n",
       " 'split1_test_score': array([0.65625   , 0.57291667, 0.61458333, 0.63541667, 0.61458333,\n",
       "        0.5625    , 0.66666667, 0.65625   , 0.59375   , 0.64583333,\n",
       "        0.58333333, 0.69791667, 0.66666667, 0.66666667, 0.63541667,\n",
       "        0.6875    , 0.59375   , 0.61458333, 0.66666667, 0.65625   ,\n",
       "        0.66666667, 0.6875    , 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.67708333, 0.69791667, 0.69791667, 0.67708333, 0.69791667,\n",
       "        0.64583333, 0.64583333, 0.70833333, 0.64583333, 0.66666667,\n",
       "        0.69791667, 0.64583333, 0.69791667, 0.69791667, 0.64583333,\n",
       "        0.70833333, 0.66666667, 0.73958333, 0.67708333, 0.67708333,\n",
       "        0.67708333, 0.69791667, 0.69791667, 0.75      , 0.67708333,\n",
       "        0.70833333, 0.70833333, 0.72916667, 0.65625   , 0.65625   ,\n",
       "        0.66666667, 0.6875    , 0.69791667, 0.72916667, 0.67708333,\n",
       "        0.73958333, 0.69791667, 0.71875   , 0.67708333, 0.6875    ,\n",
       "        0.69791667, 0.6875    , 0.75      , 0.6875    , 0.69791667,\n",
       "        0.67708333, 0.69791667, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.64583333, 0.6875    , 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.59375   , 0.5625    , 0.55208333, 0.625     , 0.60416667,\n",
       "        0.65625   , 0.63541667, 0.67708333, 0.63541667, 0.66666667,\n",
       "        0.63541667, 0.69791667, 0.64583333, 0.64583333, 0.63541667,\n",
       "        0.58333333, 0.69791667, 0.625     , 0.63541667, 0.64583333,\n",
       "        0.60416667, 0.67708333, 0.65625   , 0.65625   , 0.67708333,\n",
       "        0.61458333, 0.71875   , 0.65625   , 0.70833333, 0.66666667,\n",
       "        0.71875   , 0.66666667, 0.6875    , 0.65625   , 0.65625   ,\n",
       "        0.71875   , 0.63541667, 0.70833333, 0.67708333, 0.64583333,\n",
       "        0.63541667, 0.70833333, 0.69791667, 0.70833333, 0.66666667,\n",
       "        0.63541667, 0.65625   , 0.63541667, 0.66666667, 0.70833333,\n",
       "        0.72916667, 0.70833333, 0.73958333, 0.67708333, 0.6875    ,\n",
       "        0.69791667, 0.66666667, 0.6875    , 0.64583333, 0.70833333,\n",
       "        0.6875    , 0.75      , 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.75      , 0.78125   , 0.69791667, 0.67708333, 0.67708333,\n",
       "        0.69791667, 0.67708333, 0.71875   , 0.67708333, 0.6875    ,\n",
       "        0.70833333, 0.66666667, 0.67708333, 0.70833333, 0.69791667,\n",
       "        0.625     , 0.65625   , 0.64583333, 0.60416667, 0.58333333,\n",
       "        0.59375   , 0.65625   , 0.66666667, 0.64583333, 0.63541667,\n",
       "        0.60416667, 0.69791667, 0.66666667, 0.65625   , 0.65625   ,\n",
       "        0.64583333, 0.64583333, 0.67708333, 0.65625   , 0.65625   ,\n",
       "        0.63541667, 0.69791667, 0.65625   , 0.6875    , 0.67708333,\n",
       "        0.72916667, 0.71875   , 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.66666667, 0.625     , 0.6875    , 0.6875    , 0.63541667,\n",
       "        0.67708333, 0.72916667, 0.61458333, 0.67708333, 0.64583333,\n",
       "        0.69791667, 0.69791667, 0.71875   , 0.69791667, 0.67708333,\n",
       "        0.64583333, 0.70833333, 0.69791667, 0.69791667, 0.70833333,\n",
       "        0.69791667, 0.71875   , 0.70833333, 0.66666667, 0.66666667,\n",
       "        0.67708333, 0.73958333, 0.66666667, 0.70833333, 0.69791667,\n",
       "        0.69791667, 0.69791667, 0.67708333, 0.70833333, 0.6875    ,\n",
       "        0.63541667, 0.66666667, 0.69791667, 0.69791667, 0.6875    ,\n",
       "        0.71875   , 0.6875    , 0.73958333, 0.72916667, 0.6875    ,\n",
       "        0.70833333, 0.65625   , 0.67708333, 0.73958333, 0.75      ,\n",
       "        0.60416667, 0.625     , 0.63541667, 0.60416667, 0.57291667,\n",
       "        0.64583333, 0.69791667, 0.61458333, 0.625     , 0.61458333,\n",
       "        0.70833333, 0.67708333, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.64583333, 0.66666667, 0.65625   , 0.63541667, 0.65625   ,\n",
       "        0.6875    , 0.67708333, 0.65625   , 0.67708333, 0.67708333,\n",
       "        0.71875   , 0.67708333, 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.71875   , 0.70833333, 0.6875    , 0.64583333, 0.66666667,\n",
       "        0.6875    , 0.69791667, 0.6875    , 0.67708333, 0.625     ,\n",
       "        0.64583333, 0.66666667, 0.70833333, 0.69791667, 0.6875    ,\n",
       "        0.71875   , 0.6875    , 0.67708333, 0.71875   , 0.67708333,\n",
       "        0.65625   , 0.67708333, 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.66666667, 0.73958333, 0.71875   , 0.72916667, 0.69791667,\n",
       "        0.67708333, 0.67708333, 0.67708333, 0.72916667, 0.66666667,\n",
       "        0.67708333, 0.6875    , 0.69791667, 0.70833333, 0.73958333,\n",
       "        0.67708333, 0.71875   , 0.70833333, 0.6875    , 0.64583333,\n",
       "        0.72916667, 0.71875   , 0.66666667, 0.69791667, 0.64583333,\n",
       "        0.61458333, 0.63541667, 0.60416667, 0.63541667, 0.63541667,\n",
       "        0.60416667, 0.58333333, 0.66666667, 0.64583333, 0.625     ,\n",
       "        0.64583333, 0.67708333, 0.66666667, 0.61458333, 0.65625   ,\n",
       "        0.61458333, 0.64583333, 0.66666667, 0.65625   , 0.65625   ,\n",
       "        0.69791667, 0.65625   , 0.63541667, 0.63541667, 0.65625   ,\n",
       "        0.72916667, 0.6875    , 0.69791667, 0.67708333, 0.63541667,\n",
       "        0.63541667, 0.64583333, 0.66666667, 0.625     , 0.63541667,\n",
       "        0.60416667, 0.6875    , 0.66666667, 0.6875    , 0.65625   ,\n",
       "        0.71875   , 0.64583333, 0.67708333, 0.67708333, 0.64583333,\n",
       "        0.69791667, 0.69791667, 0.70833333, 0.66666667, 0.66666667,\n",
       "        0.69791667, 0.69791667, 0.67708333, 0.67708333, 0.64583333,\n",
       "        0.67708333, 0.66666667, 0.67708333, 0.65625   , 0.66666667,\n",
       "        0.64583333, 0.63541667, 0.6875    , 0.66666667, 0.69791667,\n",
       "        0.72916667, 0.69791667, 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.72916667, 0.6875    , 0.69791667, 0.70833333, 0.66666667,\n",
       "        0.70833333, 0.65625   , 0.6875    , 0.67708333, 0.65625   ,\n",
       "        0.59375   , 0.59375   , 0.60416667, 0.59375   , 0.61458333,\n",
       "        0.63541667, 0.64583333, 0.65625   , 0.65625   , 0.61458333,\n",
       "        0.58333333, 0.65625   , 0.67708333, 0.64583333, 0.65625   ,\n",
       "        0.625     , 0.6875    , 0.67708333, 0.65625   , 0.65625   ,\n",
       "        0.66666667, 0.69791667, 0.66666667, 0.64583333, 0.63541667,\n",
       "        0.6875    , 0.69791667, 0.64583333, 0.66666667, 0.65625   ,\n",
       "        0.65625   , 0.65625   , 0.65625   , 0.67708333, 0.65625   ,\n",
       "        0.66666667, 0.67708333, 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.6875    , 0.64583333, 0.66666667, 0.66666667, 0.63541667,\n",
       "        0.63541667, 0.6875    , 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.66666667, 0.70833333, 0.66666667, 0.66666667, 0.6875    ,\n",
       "        0.63541667, 0.69791667, 0.6875    , 0.63541667, 0.66666667,\n",
       "        0.69791667, 0.69791667, 0.6875    , 0.69791667, 0.64583333,\n",
       "        0.66666667, 0.69791667, 0.65625   , 0.67708333, 0.66666667,\n",
       "        0.66666667, 0.65625   , 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.69791667, 0.64583333, 0.6875    , 0.71875   , 0.69791667,\n",
       "        0.61458333, 0.59375   , 0.61458333, 0.625     , 0.66666667,\n",
       "        0.61458333, 0.6875    , 0.64583333, 0.625     , 0.60416667,\n",
       "        0.60416667, 0.63541667, 0.67708333, 0.64583333, 0.63541667,\n",
       "        0.60416667, 0.67708333, 0.67708333, 0.65625   , 0.64583333,\n",
       "        0.64583333, 0.64583333, 0.63541667, 0.64583333, 0.64583333,\n",
       "        0.625     , 0.64583333, 0.64583333, 0.67708333, 0.65625   ,\n",
       "        0.67708333, 0.64583333, 0.70833333, 0.67708333, 0.65625   ,\n",
       "        0.65625   , 0.72916667, 0.66666667, 0.65625   , 0.66666667,\n",
       "        0.66666667, 0.71875   , 0.66666667, 0.67708333, 0.63541667,\n",
       "        0.625     , 0.70833333, 0.64583333, 0.69791667, 0.67708333,\n",
       "        0.6875    , 0.67708333, 0.69791667, 0.67708333, 0.66666667,\n",
       "        0.67708333, 0.625     , 0.67708333, 0.67708333, 0.64583333,\n",
       "        0.70833333, 0.64583333, 0.70833333, 0.69791667, 0.67708333,\n",
       "        0.61458333, 0.66666667, 0.64583333, 0.70833333, 0.65625   ,\n",
       "        0.66666667, 0.6875    , 0.6875    , 0.67708333, 0.66666667,\n",
       "        0.6875    , 0.73958333, 0.66666667, 0.65625   , 0.6875    ,\n",
       "        0.57291667, 0.66666667, 0.65625   , 0.65625   , 0.61458333,\n",
       "        0.61458333, 0.64583333, 0.63541667, 0.65625   , 0.625     ,\n",
       "        0.64583333, 0.67708333, 0.63541667, 0.64583333, 0.67708333,\n",
       "        0.64583333, 0.625     , 0.625     , 0.63541667, 0.65625   ,\n",
       "        0.66666667, 0.625     , 0.66666667, 0.625     , 0.66666667,\n",
       "        0.70833333, 0.65625   , 0.69791667, 0.65625   , 0.64583333,\n",
       "        0.59375   , 0.66666667, 0.64583333, 0.64583333, 0.65625   ,\n",
       "        0.63541667, 0.67708333, 0.66666667, 0.67708333, 0.65625   ,\n",
       "        0.69791667, 0.75      , 0.69791667, 0.67708333, 0.67708333,\n",
       "        0.70833333, 0.67708333, 0.65625   , 0.65625   , 0.65625   ,\n",
       "        0.66666667, 0.69791667, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.625     , 0.65625   , 0.6875    , 0.66666667, 0.64583333,\n",
       "        0.64583333, 0.6875    , 0.6875    , 0.67708333, 0.6875    ,\n",
       "        0.66666667, 0.67708333, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.6875    , 0.71875   , 0.67708333, 0.66666667, 0.67708333,\n",
       "        0.6875    , 0.6875    , 0.66666667, 0.69791667, 0.65625   ]),\n",
       " 'split2_test_score': array([0.5625    , 0.61458333, 0.70833333, 0.63541667, 0.71875   ,\n",
       "        0.6875    , 0.67708333, 0.70833333, 0.67708333, 0.69791667,\n",
       "        0.71875   , 0.67708333, 0.63541667, 0.65625   , 0.69791667,\n",
       "        0.64583333, 0.63541667, 0.64583333, 0.72916667, 0.6875    ,\n",
       "        0.67708333, 0.6875    , 0.6875    , 0.69791667, 0.67708333,\n",
       "        0.6875    , 0.67708333, 0.69791667, 0.69791667, 0.67708333,\n",
       "        0.61458333, 0.66666667, 0.71875   , 0.6875    , 0.71875   ,\n",
       "        0.65625   , 0.66666667, 0.69791667, 0.69791667, 0.66666667,\n",
       "        0.72916667, 0.66666667, 0.66666667, 0.71875   , 0.66666667,\n",
       "        0.625     , 0.65625   , 0.71875   , 0.69791667, 0.71875   ,\n",
       "        0.6875    , 0.69791667, 0.70833333, 0.6875    , 0.70833333,\n",
       "        0.58333333, 0.66666667, 0.625     , 0.67708333, 0.69791667,\n",
       "        0.59375   , 0.65625   , 0.6875    , 0.70833333, 0.70833333,\n",
       "        0.64583333, 0.6875    , 0.67708333, 0.71875   , 0.69791667,\n",
       "        0.66666667, 0.63541667, 0.70833333, 0.69791667, 0.70833333,\n",
       "        0.60416667, 0.66666667, 0.70833333, 0.65625   , 0.71875   ,\n",
       "        0.59375   , 0.69791667, 0.69791667, 0.6875    , 0.70833333,\n",
       "        0.60416667, 0.64583333, 0.69791667, 0.64583333, 0.66666667,\n",
       "        0.67708333, 0.63541667, 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.63541667, 0.66666667, 0.6875    , 0.6875    , 0.69791667,\n",
       "        0.65625   , 0.625     , 0.70833333, 0.70833333, 0.71875   ,\n",
       "        0.70833333, 0.67708333, 0.69791667, 0.70833333, 0.69791667,\n",
       "        0.64583333, 0.66666667, 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.625     , 0.6875    , 0.72916667, 0.69791667, 0.69791667,\n",
       "        0.6875    , 0.65625   , 0.69791667, 0.6875    , 0.69791667,\n",
       "        0.67708333, 0.69791667, 0.6875    , 0.67708333, 0.6875    ,\n",
       "        0.58333333, 0.66666667, 0.65625   , 0.66666667, 0.66666667,\n",
       "        0.60416667, 0.59375   , 0.6875    , 0.70833333, 0.6875    ,\n",
       "        0.66666667, 0.64583333, 0.64583333, 0.67708333, 0.6875    ,\n",
       "        0.66666667, 0.69791667, 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.58333333, 0.64583333, 0.67708333, 0.65625   , 0.65625   ,\n",
       "        0.63541667, 0.625     , 0.67708333, 0.67708333, 0.65625   ,\n",
       "        0.67708333, 0.61458333, 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.60416667, 0.73958333, 0.6875    , 0.73958333, 0.6875    ,\n",
       "        0.625     , 0.64583333, 0.69791667, 0.66666667, 0.69791667,\n",
       "        0.6875    , 0.67708333, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.63541667, 0.69791667, 0.67708333, 0.66666667, 0.67708333,\n",
       "        0.65625   , 0.65625   , 0.69791667, 0.71875   , 0.76041667,\n",
       "        0.64583333, 0.65625   , 0.70833333, 0.73958333, 0.69791667,\n",
       "        0.66666667, 0.6875    , 0.66666667, 0.66666667, 0.66666667,\n",
       "        0.57291667, 0.66666667, 0.67708333, 0.67708333, 0.69791667,\n",
       "        0.65625   , 0.67708333, 0.67708333, 0.66666667, 0.73958333,\n",
       "        0.65625   , 0.71875   , 0.67708333, 0.69791667, 0.66666667,\n",
       "        0.71875   , 0.67708333, 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.61458333, 0.625     , 0.625     , 0.69791667, 0.66666667,\n",
       "        0.67708333, 0.6875    , 0.67708333, 0.6875    , 0.65625   ,\n",
       "        0.66666667, 0.65625   , 0.66666667, 0.75      , 0.6875    ,\n",
       "        0.66666667, 0.67708333, 0.71875   , 0.6875    , 0.70833333,\n",
       "        0.59375   , 0.67708333, 0.6875    , 0.67708333, 0.73958333,\n",
       "        0.64583333, 0.625     , 0.69791667, 0.66666667, 0.69791667,\n",
       "        0.67708333, 0.66666667, 0.6875    , 0.70833333, 0.66666667,\n",
       "        0.66666667, 0.71875   , 0.69791667, 0.6875    , 0.6875    ,\n",
       "        0.63541667, 0.64583333, 0.67708333, 0.67708333, 0.66666667,\n",
       "        0.6875    , 0.6875    , 0.67708333, 0.67708333, 0.71875   ,\n",
       "        0.69791667, 0.6875    , 0.67708333, 0.69791667, 0.69791667,\n",
       "        0.69791667, 0.6875    , 0.67708333, 0.71875   , 0.67708333,\n",
       "        0.65625   , 0.65625   , 0.6875    , 0.6875    , 0.69791667,\n",
       "        0.61458333, 0.67708333, 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.63541667, 0.65625   , 0.70833333, 0.66666667, 0.71875   ,\n",
       "        0.625     , 0.67708333, 0.69791667, 0.71875   , 0.6875    ,\n",
       "        0.69791667, 0.63541667, 0.71875   , 0.6875    , 0.67708333,\n",
       "        0.65625   , 0.64583333, 0.71875   , 0.64583333, 0.6875    ,\n",
       "        0.63541667, 0.64583333, 0.63541667, 0.73958333, 0.69791667,\n",
       "        0.69791667, 0.67708333, 0.67708333, 0.70833333, 0.6875    ,\n",
       "        0.66666667, 0.66666667, 0.6875    , 0.70833333, 0.70833333,\n",
       "        0.625     , 0.59375   , 0.67708333, 0.67708333, 0.70833333,\n",
       "        0.61458333, 0.65625   , 0.69791667, 0.72916667, 0.6875    ,\n",
       "        0.69791667, 0.67708333, 0.67708333, 0.69791667, 0.65625   ,\n",
       "        0.6875    , 0.6875    , 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.57291667, 0.66666667, 0.625     , 0.67708333, 0.70833333,\n",
       "        0.59375   , 0.70833333, 0.66666667, 0.70833333, 0.6875    ,\n",
       "        0.64583333, 0.67708333, 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.58333333, 0.66666667, 0.6875    , 0.69791667, 0.65625   ,\n",
       "        0.71875   , 0.6875    , 0.6875    , 0.69791667, 0.69791667,\n",
       "        0.65625   , 0.65625   , 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.63541667, 0.6875    , 0.67708333, 0.70833333, 0.67708333,\n",
       "        0.64583333, 0.60416667, 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.54166667, 0.66666667, 0.66666667, 0.67708333, 0.67708333,\n",
       "        0.71875   , 0.625     , 0.63541667, 0.70833333, 0.70833333,\n",
       "        0.6875    , 0.63541667, 0.67708333, 0.69791667, 0.69791667,\n",
       "        0.70833333, 0.6875    , 0.63541667, 0.71875   , 0.64583333,\n",
       "        0.70833333, 0.65625   , 0.65625   , 0.65625   , 0.70833333,\n",
       "        0.58333333, 0.73958333, 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.58333333, 0.67708333, 0.64583333, 0.66666667, 0.70833333,\n",
       "        0.63541667, 0.66666667, 0.67708333, 0.69791667, 0.66666667,\n",
       "        0.65625   , 0.6875    , 0.71875   , 0.69791667, 0.67708333,\n",
       "        0.67708333, 0.64583333, 0.65625   , 0.71875   , 0.71875   ,\n",
       "        0.66666667, 0.6875    , 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.64583333, 0.66666667, 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.625     , 0.67708333, 0.69791667, 0.66666667, 0.67708333,\n",
       "        0.71875   , 0.67708333, 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.69791667, 0.65625   , 0.6875    , 0.65625   , 0.70833333,\n",
       "        0.67708333, 0.66666667, 0.67708333, 0.66666667, 0.65625   ,\n",
       "        0.6875    , 0.64583333, 0.64583333, 0.66666667, 0.6875    ,\n",
       "        0.67708333, 0.65625   , 0.6875    , 0.67708333, 0.66666667,\n",
       "        0.64583333, 0.66666667, 0.6875    , 0.67708333, 0.6875    ,\n",
       "        0.60416667, 0.65625   , 0.64583333, 0.67708333, 0.71875   ,\n",
       "        0.60416667, 0.64583333, 0.67708333, 0.6875    , 0.71875   ,\n",
       "        0.625     , 0.71875   , 0.67708333, 0.70833333, 0.66666667,\n",
       "        0.65625   , 0.64583333, 0.66666667, 0.66666667, 0.66666667,\n",
       "        0.66666667, 0.64583333, 0.63541667, 0.6875    , 0.6875    ,\n",
       "        0.64583333, 0.66666667, 0.69791667, 0.69791667, 0.70833333,\n",
       "        0.63541667, 0.6875    , 0.69791667, 0.66666667, 0.65625   ,\n",
       "        0.59375   , 0.63541667, 0.6875    , 0.67708333, 0.69791667,\n",
       "        0.59375   , 0.71875   , 0.6875    , 0.66666667, 0.6875    ,\n",
       "        0.65625   , 0.625     , 0.65625   , 0.65625   , 0.69791667,\n",
       "        0.61458333, 0.67708333, 0.70833333, 0.67708333, 0.6875    ,\n",
       "        0.65625   , 0.72916667, 0.64583333, 0.6875    , 0.65625   ,\n",
       "        0.64583333, 0.63541667, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.58333333, 0.54166667, 0.6875    , 0.69791667, 0.6875    ,\n",
       "        0.63541667, 0.65625   , 0.66666667, 0.67708333, 0.6875    ,\n",
       "        0.73958333, 0.67708333, 0.65625   , 0.67708333, 0.6875    ,\n",
       "        0.63541667, 0.65625   , 0.67708333, 0.6875    , 0.71875   ,\n",
       "        0.67708333, 0.69791667, 0.64583333, 0.67708333, 0.6875    ,\n",
       "        0.57291667, 0.64583333, 0.67708333, 0.66666667, 0.69791667,\n",
       "        0.625     , 0.69791667, 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.63541667, 0.64583333, 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.6875    , 0.73958333, 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.63541667, 0.67708333, 0.65625   , 0.67708333, 0.6875    ,\n",
       "        0.73958333, 0.66666667, 0.64583333, 0.70833333, 0.69791667,\n",
       "        0.63541667, 0.6875    , 0.67708333, 0.70833333, 0.67708333,\n",
       "        0.64583333, 0.66666667, 0.66666667, 0.69791667, 0.69791667,\n",
       "        0.67708333, 0.63541667, 0.65625   , 0.69791667, 0.66666667,\n",
       "        0.66666667, 0.69791667, 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.67708333, 0.63541667, 0.65625   , 0.66666667, 0.70833333,\n",
       "        0.71875   , 0.64583333, 0.65625   , 0.66666667, 0.66666667,\n",
       "        0.625     , 0.64583333, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.64583333, 0.71875   , 0.625     , 0.70833333, 0.66666667]),\n",
       " 'split3_test_score': array([0.69791667, 0.71875   , 0.78125   , 0.75      , 0.73958333,\n",
       "        0.69791667, 0.71875   , 0.77083333, 0.76041667, 0.77083333,\n",
       "        0.70833333, 0.71875   , 0.73958333, 0.77083333, 0.78125   ,\n",
       "        0.65625   , 0.72916667, 0.79166667, 0.78125   , 0.75      ,\n",
       "        0.69791667, 0.71875   , 0.78125   , 0.78125   , 0.79166667,\n",
       "        0.67708333, 0.75      , 0.73958333, 0.71875   , 0.73958333,\n",
       "        0.71875   , 0.70833333, 0.72916667, 0.80208333, 0.75      ,\n",
       "        0.76041667, 0.77083333, 0.69791667, 0.77083333, 0.76041667,\n",
       "        0.67708333, 0.73958333, 0.78125   , 0.73958333, 0.77083333,\n",
       "        0.72916667, 0.73958333, 0.77083333, 0.75      , 0.76041667,\n",
       "        0.69791667, 0.75      , 0.70833333, 0.75      , 0.77083333,\n",
       "        0.66666667, 0.71875   , 0.72916667, 0.72916667, 0.72916667,\n",
       "        0.75      , 0.65625   , 0.80208333, 0.77083333, 0.75      ,\n",
       "        0.6875    , 0.64583333, 0.78125   , 0.70833333, 0.71875   ,\n",
       "        0.79166667, 0.73958333, 0.76041667, 0.77083333, 0.75      ,\n",
       "        0.71875   , 0.72916667, 0.78125   , 0.73958333, 0.77083333,\n",
       "        0.71875   , 0.77083333, 0.78125   , 0.78125   , 0.76041667,\n",
       "        0.64583333, 0.72916667, 0.77083333, 0.76041667, 0.78125   ,\n",
       "        0.69791667, 0.72916667, 0.79166667, 0.76041667, 0.80208333,\n",
       "        0.6875    , 0.73958333, 0.73958333, 0.77083333, 0.76041667,\n",
       "        0.76041667, 0.76041667, 0.73958333, 0.79166667, 0.78125   ,\n",
       "        0.70833333, 0.73958333, 0.80208333, 0.75      , 0.76041667,\n",
       "        0.73958333, 0.73958333, 0.67708333, 0.77083333, 0.76041667,\n",
       "        0.67708333, 0.72916667, 0.73958333, 0.78125   , 0.76041667,\n",
       "        0.72916667, 0.73958333, 0.76041667, 0.76041667, 0.77083333,\n",
       "        0.77083333, 0.75      , 0.73958333, 0.75      , 0.76041667,\n",
       "        0.6875    , 0.75      , 0.75      , 0.70833333, 0.76041667,\n",
       "        0.69791667, 0.75      , 0.76041667, 0.78125   , 0.73958333,\n",
       "        0.77083333, 0.80208333, 0.77083333, 0.75      , 0.72916667,\n",
       "        0.73958333, 0.72916667, 0.75      , 0.76041667, 0.75      ,\n",
       "        0.67708333, 0.71875   , 0.73958333, 0.79166667, 0.73958333,\n",
       "        0.70833333, 0.76041667, 0.73958333, 0.76041667, 0.79166667,\n",
       "        0.69791667, 0.77083333, 0.79166667, 0.77083333, 0.77083333,\n",
       "        0.75      , 0.71875   , 0.80208333, 0.76041667, 0.75      ,\n",
       "        0.6875    , 0.77083333, 0.78125   , 0.72916667, 0.77083333,\n",
       "        0.71875   , 0.8125    , 0.75      , 0.80208333, 0.76041667,\n",
       "        0.78125   , 0.72916667, 0.76041667, 0.78125   , 0.71875   ,\n",
       "        0.75      , 0.80208333, 0.77083333, 0.73958333, 0.73958333,\n",
       "        0.66666667, 0.80208333, 0.75      , 0.78125   , 0.77083333,\n",
       "        0.79166667, 0.73958333, 0.75      , 0.73958333, 0.76041667,\n",
       "        0.67708333, 0.70833333, 0.77083333, 0.75      , 0.73958333,\n",
       "        0.70833333, 0.75      , 0.76041667, 0.75      , 0.78125   ,\n",
       "        0.76041667, 0.79166667, 0.72916667, 0.77083333, 0.77083333,\n",
       "        0.69791667, 0.71875   , 0.78125   , 0.71875   , 0.73958333,\n",
       "        0.71875   , 0.72916667, 0.72916667, 0.72916667, 0.76041667,\n",
       "        0.71875   , 0.77083333, 0.78125   , 0.75      , 0.75      ,\n",
       "        0.73958333, 0.78125   , 0.72916667, 0.73958333, 0.73958333,\n",
       "        0.77083333, 0.76041667, 0.75      , 0.77083333, 0.76041667,\n",
       "        0.70833333, 0.71875   , 0.67708333, 0.75      , 0.73958333,\n",
       "        0.66666667, 0.73958333, 0.72916667, 0.75      , 0.76041667,\n",
       "        0.69791667, 0.70833333, 0.77083333, 0.79166667, 0.77083333,\n",
       "        0.77083333, 0.73958333, 0.73958333, 0.77083333, 0.76041667,\n",
       "        0.71875   , 0.69791667, 0.75      , 0.79166667, 0.73958333,\n",
       "        0.71875   , 0.71875   , 0.75      , 0.75      , 0.77083333,\n",
       "        0.67708333, 0.72916667, 0.76041667, 0.8125    , 0.77083333,\n",
       "        0.75      , 0.71875   , 0.75      , 0.73958333, 0.79166667,\n",
       "        0.71875   , 0.75      , 0.73958333, 0.75      , 0.76041667,\n",
       "        0.69791667, 0.77083333, 0.77083333, 0.72916667, 0.78125   ,\n",
       "        0.70833333, 0.80208333, 0.77083333, 0.75      , 0.75      ,\n",
       "        0.71875   , 0.70833333, 0.70833333, 0.75      , 0.75      ,\n",
       "        0.69791667, 0.71875   , 0.76041667, 0.75      , 0.75      ,\n",
       "        0.73958333, 0.79166667, 0.69791667, 0.6875    , 0.72916667,\n",
       "        0.66666667, 0.8125    , 0.77083333, 0.75      , 0.77083333,\n",
       "        0.70833333, 0.75      , 0.78125   , 0.72916667, 0.76041667,\n",
       "        0.75      , 0.69791667, 0.72916667, 0.71875   , 0.72916667,\n",
       "        0.73958333, 0.77083333, 0.73958333, 0.73958333, 0.71875   ,\n",
       "        0.70833333, 0.71875   , 0.79166667, 0.78125   , 0.79166667,\n",
       "        0.71875   , 0.72916667, 0.76041667, 0.78125   , 0.77083333,\n",
       "        0.75      , 0.77083333, 0.78125   , 0.75      , 0.72916667,\n",
       "        0.75      , 0.69791667, 0.72916667, 0.73958333, 0.75      ,\n",
       "        0.76041667, 0.72916667, 0.72916667, 0.73958333, 0.78125   ,\n",
       "        0.77083333, 0.72916667, 0.70833333, 0.77083333, 0.76041667,\n",
       "        0.79166667, 0.70833333, 0.78125   , 0.73958333, 0.77083333,\n",
       "        0.73958333, 0.77083333, 0.71875   , 0.76041667, 0.76041667,\n",
       "        0.71875   , 0.79166667, 0.73958333, 0.73958333, 0.76041667,\n",
       "        0.72916667, 0.75      , 0.76041667, 0.75      , 0.77083333,\n",
       "        0.75      , 0.79166667, 0.78125   , 0.77083333, 0.75      ,\n",
       "        0.72916667, 0.78125   , 0.78125   , 0.76041667, 0.75      ,\n",
       "        0.66666667, 0.76041667, 0.71875   , 0.76041667, 0.78125   ,\n",
       "        0.76041667, 0.70833333, 0.78125   , 0.75      , 0.71875   ,\n",
       "        0.72916667, 0.76041667, 0.77083333, 0.78125   , 0.75      ,\n",
       "        0.71875   , 0.71875   , 0.79166667, 0.69791667, 0.75      ,\n",
       "        0.72916667, 0.79166667, 0.75      , 0.75      , 0.72916667,\n",
       "        0.6875    , 0.72916667, 0.75      , 0.71875   , 0.78125   ,\n",
       "        0.71875   , 0.67708333, 0.78125   , 0.79166667, 0.78125   ,\n",
       "        0.73958333, 0.71875   , 0.78125   , 0.75      , 0.78125   ,\n",
       "        0.625     , 0.71875   , 0.70833333, 0.76041667, 0.78125   ,\n",
       "        0.79166667, 0.78125   , 0.72916667, 0.73958333, 0.75      ,\n",
       "        0.71875   , 0.76041667, 0.73958333, 0.77083333, 0.75      ,\n",
       "        0.6875    , 0.8125    , 0.77083333, 0.76041667, 0.76041667,\n",
       "        0.67708333, 0.77083333, 0.71875   , 0.73958333, 0.72916667,\n",
       "        0.71875   , 0.76041667, 0.75      , 0.73958333, 0.73958333,\n",
       "        0.6875    , 0.76041667, 0.72916667, 0.77083333, 0.72916667,\n",
       "        0.70833333, 0.75      , 0.69791667, 0.80208333, 0.70833333,\n",
       "        0.80208333, 0.77083333, 0.76041667, 0.73958333, 0.77083333,\n",
       "        0.69791667, 0.76041667, 0.79166667, 0.76041667, 0.77083333,\n",
       "        0.6875    , 0.72916667, 0.70833333, 0.72916667, 0.72916667,\n",
       "        0.71875   , 0.70833333, 0.80208333, 0.72916667, 0.78125   ,\n",
       "        0.80208333, 0.70833333, 0.76041667, 0.76041667, 0.71875   ,\n",
       "        0.69791667, 0.75      , 0.78125   , 0.79166667, 0.75      ,\n",
       "        0.73958333, 0.71875   , 0.80208333, 0.78125   , 0.77083333,\n",
       "        0.71875   , 0.6875    , 0.70833333, 0.76041667, 0.72916667,\n",
       "        0.6875    , 0.76041667, 0.77083333, 0.75      , 0.76041667,\n",
       "        0.70833333, 0.69791667, 0.75      , 0.76041667, 0.75      ,\n",
       "        0.78125   , 0.76041667, 0.73958333, 0.71875   , 0.77083333,\n",
       "        0.76041667, 0.70833333, 0.73958333, 0.73958333, 0.77083333,\n",
       "        0.75      , 0.76041667, 0.76041667, 0.71875   , 0.75      ,\n",
       "        0.75      , 0.75      , 0.75      , 0.76041667, 0.75      ,\n",
       "        0.72916667, 0.73958333, 0.73958333, 0.77083333, 0.75      ,\n",
       "        0.73958333, 0.75      , 0.73958333, 0.75      , 0.73958333,\n",
       "        0.6875    , 0.79166667, 0.76041667, 0.71875   , 0.76041667,\n",
       "        0.64583333, 0.67708333, 0.75      , 0.75      , 0.75      ,\n",
       "        0.67708333, 0.71875   , 0.76041667, 0.80208333, 0.73958333,\n",
       "        0.65625   , 0.77083333, 0.66666667, 0.73958333, 0.75      ,\n",
       "        0.72916667, 0.72916667, 0.75      , 0.78125   , 0.76041667,\n",
       "        0.72916667, 0.75      , 0.73958333, 0.78125   , 0.76041667,\n",
       "        0.69791667, 0.75      , 0.71875   , 0.80208333, 0.78125   ,\n",
       "        0.75      , 0.76041667, 0.77083333, 0.76041667, 0.78125   ,\n",
       "        0.72916667, 0.69791667, 0.75      , 0.73958333, 0.71875   ,\n",
       "        0.6875    , 0.72916667, 0.77083333, 0.73958333, 0.78125   ,\n",
       "        0.72916667, 0.76041667, 0.73958333, 0.73958333, 0.77083333,\n",
       "        0.73958333, 0.73958333, 0.75      , 0.72916667, 0.75      ,\n",
       "        0.6875    , 0.71875   , 0.75      , 0.77083333, 0.75      ,\n",
       "        0.67708333, 0.76041667, 0.77083333, 0.75      , 0.72916667,\n",
       "        0.77083333, 0.65625   , 0.73958333, 0.76041667, 0.75      ,\n",
       "        0.6875    , 0.77083333, 0.77083333, 0.77083333, 0.76041667,\n",
       "        0.70833333, 0.69791667, 0.6875    , 0.77083333, 0.75      ,\n",
       "        0.70833333, 0.71875   , 0.75      , 0.75      , 0.77083333]),\n",
       " 'split4_test_score': array([0.625     , 0.6875    , 0.69791667, 0.70833333, 0.67708333,\n",
       "        0.64583333, 0.66666667, 0.69791667, 0.6875    , 0.69791667,\n",
       "        0.69791667, 0.72916667, 0.71875   , 0.6875    , 0.72916667,\n",
       "        0.70833333, 0.6875    , 0.71875   , 0.6875    , 0.69791667,\n",
       "        0.66666667, 0.77083333, 0.75      , 0.72916667, 0.73958333,\n",
       "        0.72916667, 0.70833333, 0.73958333, 0.72916667, 0.70833333,\n",
       "        0.78125   , 0.66666667, 0.75      , 0.70833333, 0.70833333,\n",
       "        0.71875   , 0.63541667, 0.70833333, 0.70833333, 0.71875   ,\n",
       "        0.67708333, 0.625     , 0.75      , 0.73958333, 0.70833333,\n",
       "        0.72916667, 0.77083333, 0.72916667, 0.71875   , 0.75      ,\n",
       "        0.6875    , 0.69791667, 0.69791667, 0.71875   , 0.69791667,\n",
       "        0.57291667, 0.69791667, 0.73958333, 0.73958333, 0.72916667,\n",
       "        0.69791667, 0.67708333, 0.73958333, 0.70833333, 0.6875    ,\n",
       "        0.71875   , 0.70833333, 0.71875   , 0.70833333, 0.72916667,\n",
       "        0.73958333, 0.65625   , 0.69791667, 0.69791667, 0.69791667,\n",
       "        0.73958333, 0.69791667, 0.70833333, 0.67708333, 0.65625   ,\n",
       "        0.63541667, 0.67708333, 0.67708333, 0.69791667, 0.70833333,\n",
       "        0.625     , 0.625     , 0.66666667, 0.71875   , 0.6875    ,\n",
       "        0.71875   , 0.72916667, 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.64583333, 0.72916667, 0.6875    , 0.66666667, 0.71875   ,\n",
       "        0.6875    , 0.76041667, 0.67708333, 0.6875    , 0.71875   ,\n",
       "        0.70833333, 0.71875   , 0.70833333, 0.69791667, 0.6875    ,\n",
       "        0.6875    , 0.67708333, 0.72916667, 0.72916667, 0.72916667,\n",
       "        0.63541667, 0.70833333, 0.75      , 0.70833333, 0.72916667,\n",
       "        0.70833333, 0.76041667, 0.67708333, 0.6875    , 0.70833333,\n",
       "        0.65625   , 0.70833333, 0.75      , 0.71875   , 0.72916667,\n",
       "        0.70833333, 0.72916667, 0.6875    , 0.67708333, 0.72916667,\n",
       "        0.70833333, 0.71875   , 0.70833333, 0.71875   , 0.71875   ,\n",
       "        0.72916667, 0.5625    , 0.78125   , 0.6875    , 0.69791667,\n",
       "        0.6875    , 0.70833333, 0.61458333, 0.67708333, 0.67708333,\n",
       "        0.69791667, 0.69791667, 0.70833333, 0.69791667, 0.71875   ,\n",
       "        0.70833333, 0.61458333, 0.79166667, 0.70833333, 0.64583333,\n",
       "        0.60416667, 0.6875    , 0.58333333, 0.71875   , 0.69791667,\n",
       "        0.625     , 0.6875    , 0.72916667, 0.67708333, 0.67708333,\n",
       "        0.75      , 0.66666667, 0.70833333, 0.71875   , 0.71875   ,\n",
       "        0.70833333, 0.6875    , 0.71875   , 0.6875    , 0.72916667,\n",
       "        0.71875   , 0.70833333, 0.72916667, 0.72916667, 0.71875   ,\n",
       "        0.66666667, 0.66666667, 0.72916667, 0.71875   , 0.71875   ,\n",
       "        0.65625   , 0.71875   , 0.73958333, 0.72916667, 0.71875   ,\n",
       "        0.70833333, 0.73958333, 0.6875    , 0.69791667, 0.71875   ,\n",
       "        0.63541667, 0.70833333, 0.72916667, 0.70833333, 0.72916667,\n",
       "        0.67708333, 0.76041667, 0.73958333, 0.73958333, 0.71875   ,\n",
       "        0.75      , 0.69791667, 0.75      , 0.72916667, 0.71875   ,\n",
       "        0.65625   , 0.67708333, 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.61458333, 0.69791667, 0.69791667, 0.6875    , 0.66666667,\n",
       "        0.72916667, 0.66666667, 0.67708333, 0.66666667, 0.6875    ,\n",
       "        0.72916667, 0.65625   , 0.69791667, 0.71875   , 0.71875   ,\n",
       "        0.64583333, 0.72916667, 0.75      , 0.64583333, 0.65625   ,\n",
       "        0.64583333, 0.69791667, 0.6875    , 0.67708333, 0.69791667,\n",
       "        0.64583333, 0.69791667, 0.67708333, 0.70833333, 0.67708333,\n",
       "        0.72916667, 0.71875   , 0.70833333, 0.6875    , 0.67708333,\n",
       "        0.72916667, 0.6875    , 0.69791667, 0.69791667, 0.70833333,\n",
       "        0.77083333, 0.6875    , 0.75      , 0.71875   , 0.72916667,\n",
       "        0.6875    , 0.69791667, 0.71875   , 0.72916667, 0.72916667,\n",
       "        0.71875   , 0.6875    , 0.72916667, 0.70833333, 0.72916667,\n",
       "        0.61458333, 0.72916667, 0.67708333, 0.70833333, 0.72916667,\n",
       "        0.61458333, 0.72916667, 0.71875   , 0.73958333, 0.70833333,\n",
       "        0.76041667, 0.70833333, 0.77083333, 0.75      , 0.70833333,\n",
       "        0.70833333, 0.69791667, 0.71875   , 0.72916667, 0.71875   ,\n",
       "        0.71875   , 0.71875   , 0.75      , 0.67708333, 0.72916667,\n",
       "        0.55208333, 0.8125    , 0.73958333, 0.67708333, 0.6875    ,\n",
       "        0.625     , 0.65625   , 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.63541667, 0.76041667, 0.70833333, 0.69791667, 0.70833333,\n",
       "        0.70833333, 0.64583333, 0.60416667, 0.70833333, 0.72916667,\n",
       "        0.65625   , 0.6875    , 0.6875    , 0.71875   , 0.72916667,\n",
       "        0.70833333, 0.6875    , 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.65625   , 0.71875   , 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.70833333, 0.65625   , 0.6875    , 0.67708333, 0.71875   ,\n",
       "        0.69791667, 0.72916667, 0.70833333, 0.73958333, 0.71875   ,\n",
       "        0.69791667, 0.69791667, 0.69791667, 0.73958333, 0.75      ,\n",
       "        0.72916667, 0.73958333, 0.76041667, 0.69791667, 0.72916667,\n",
       "        0.6875    , 0.70833333, 0.69791667, 0.71875   , 0.69791667,\n",
       "        0.64583333, 0.70833333, 0.76041667, 0.72916667, 0.70833333,\n",
       "        0.67708333, 0.60416667, 0.70833333, 0.70833333, 0.73958333,\n",
       "        0.75      , 0.69791667, 0.71875   , 0.72916667, 0.72916667,\n",
       "        0.60416667, 0.67708333, 0.73958333, 0.72916667, 0.76041667,\n",
       "        0.75      , 0.67708333, 0.70833333, 0.71875   , 0.71875   ,\n",
       "        0.69791667, 0.6875    , 0.70833333, 0.71875   , 0.72916667,\n",
       "        0.71875   , 0.61458333, 0.72916667, 0.70833333, 0.72916667,\n",
       "        0.6875    , 0.78125   , 0.6875    , 0.71875   , 0.65625   ,\n",
       "        0.70833333, 0.69791667, 0.69791667, 0.72916667, 0.70833333,\n",
       "        0.6875    , 0.6875    , 0.72916667, 0.71875   , 0.69791667,\n",
       "        0.69791667, 0.70833333, 0.71875   , 0.69791667, 0.71875   ,\n",
       "        0.71875   , 0.69791667, 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.67708333, 0.64583333, 0.6875    , 0.72916667, 0.71875   ,\n",
       "        0.66666667, 0.64583333, 0.71875   , 0.71875   , 0.73958333,\n",
       "        0.66666667, 0.72916667, 0.67708333, 0.73958333, 0.71875   ,\n",
       "        0.65625   , 0.70833333, 0.75      , 0.69791667, 0.71875   ,\n",
       "        0.66666667, 0.77083333, 0.72916667, 0.69791667, 0.72916667,\n",
       "        0.73958333, 0.625     , 0.72916667, 0.71875   , 0.70833333,\n",
       "        0.70833333, 0.6875    , 0.70833333, 0.69791667, 0.70833333,\n",
       "        0.70833333, 0.71875   , 0.67708333, 0.72916667, 0.72916667,\n",
       "        0.72916667, 0.72916667, 0.70833333, 0.6875    , 0.70833333,\n",
       "        0.59375   , 0.67708333, 0.75      , 0.70833333, 0.71875   ,\n",
       "        0.64583333, 0.625     , 0.72916667, 0.69791667, 0.69791667,\n",
       "        0.75      , 0.71875   , 0.77083333, 0.73958333, 0.72916667,\n",
       "        0.75      , 0.625     , 0.70833333, 0.70833333, 0.70833333,\n",
       "        0.65625   , 0.70833333, 0.66666667, 0.71875   , 0.69791667,\n",
       "        0.72916667, 0.69791667, 0.67708333, 0.70833333, 0.70833333,\n",
       "        0.6875    , 0.65625   , 0.70833333, 0.72916667, 0.69791667,\n",
       "        0.6875    , 0.75      , 0.70833333, 0.71875   , 0.70833333,\n",
       "        0.70833333, 0.71875   , 0.71875   , 0.70833333, 0.69791667,\n",
       "        0.71875   , 0.76041667, 0.73958333, 0.75      , 0.72916667,\n",
       "        0.72916667, 0.73958333, 0.70833333, 0.73958333, 0.71875   ,\n",
       "        0.75      , 0.72916667, 0.71875   , 0.71875   , 0.72916667,\n",
       "        0.69791667, 0.6875    , 0.70833333, 0.73958333, 0.70833333,\n",
       "        0.77083333, 0.70833333, 0.64583333, 0.71875   , 0.69791667,\n",
       "        0.71875   , 0.70833333, 0.72916667, 0.71875   , 0.71875   ,\n",
       "        0.72916667, 0.6875    , 0.71875   , 0.72916667, 0.71875   ,\n",
       "        0.70833333, 0.66666667, 0.65625   , 0.71875   , 0.71875   ,\n",
       "        0.70833333, 0.79166667, 0.73958333, 0.72916667, 0.71875   ,\n",
       "        0.72916667, 0.65625   , 0.69791667, 0.65625   , 0.69791667,\n",
       "        0.67708333, 0.69791667, 0.6875    , 0.6875    , 0.71875   ,\n",
       "        0.625     , 0.67708333, 0.72916667, 0.72916667, 0.73958333,\n",
       "        0.71875   , 0.67708333, 0.69791667, 0.70833333, 0.71875   ,\n",
       "        0.64583333, 0.66666667, 0.70833333, 0.6875    , 0.71875   ,\n",
       "        0.6875    , 0.67708333, 0.75      , 0.70833333, 0.72916667,\n",
       "        0.6875    , 0.6875    , 0.71875   , 0.73958333, 0.72916667,\n",
       "        0.75      , 0.70833333, 0.69791667, 0.69791667, 0.70833333,\n",
       "        0.65625   , 0.70833333, 0.69791667, 0.70833333, 0.72916667,\n",
       "        0.65625   , 0.6875    , 0.75      , 0.72916667, 0.70833333,\n",
       "        0.71875   , 0.65625   , 0.73958333, 0.69791667, 0.71875   ,\n",
       "        0.58333333, 0.69791667, 0.72916667, 0.75      , 0.75      ,\n",
       "        0.71875   , 0.64583333, 0.75      , 0.71875   , 0.71875   ,\n",
       "        0.72916667, 0.66666667, 0.70833333, 0.69791667, 0.69791667,\n",
       "        0.60416667, 0.71875   , 0.69791667, 0.73958333, 0.72916667,\n",
       "        0.58333333, 0.73958333, 0.64583333, 0.72916667, 0.67708333,\n",
       "        0.6875    , 0.66666667, 0.71875   , 0.71875   , 0.71875   ]),\n",
       " 'mean_test_score': array([0.6375    , 0.6375    , 0.6875    , 0.675     , 0.67708333,\n",
       "        0.66041667, 0.68333333, 0.69375   , 0.66875   , 0.68958333,\n",
       "        0.67916667, 0.68541667, 0.67291667, 0.68333333, 0.69583333,\n",
       "        0.66875   , 0.64791667, 0.68541667, 0.70416667, 0.68333333,\n",
       "        0.66041667, 0.68958333, 0.71458333, 0.70625   , 0.70625   ,\n",
       "        0.70416667, 0.68958333, 0.70208333, 0.69791667, 0.68541667,\n",
       "        0.67708333, 0.67291667, 0.71458333, 0.68958333, 0.7       ,\n",
       "        0.7       , 0.67291667, 0.68958333, 0.70625   , 0.68541667,\n",
       "        0.6875    , 0.6625    , 0.72291667, 0.70625   , 0.69791667,\n",
       "        0.67291667, 0.69375   , 0.70416667, 0.7125    , 0.70625   ,\n",
       "        0.67083333, 0.70833333, 0.68958333, 0.68333333, 0.69375   ,\n",
       "        0.62916667, 0.68541667, 0.6875    , 0.70416667, 0.69583333,\n",
       "        0.67708333, 0.67916667, 0.71875   , 0.71041667, 0.69166667,\n",
       "        0.68958333, 0.6875    , 0.70625   , 0.69166667, 0.7       ,\n",
       "        0.6875    , 0.6875    , 0.68958333, 0.69583333, 0.69375   ,\n",
       "        0.675     , 0.6875    , 0.70208333, 0.68125   , 0.6875    ,\n",
       "        0.63125   , 0.66666667, 0.67291667, 0.68125   , 0.67916667,\n",
       "        0.6375    , 0.66041667, 0.68958333, 0.67708333, 0.68958333,\n",
       "        0.68333333, 0.67916667, 0.69375   , 0.69791667, 0.69583333,\n",
       "        0.64166667, 0.71041667, 0.675     , 0.68958333, 0.69375   ,\n",
       "        0.675     , 0.7       , 0.67916667, 0.7       , 0.70416667,\n",
       "        0.68333333, 0.70625   , 0.7       , 0.70208333, 0.70208333,\n",
       "        0.69166667, 0.67916667, 0.69166667, 0.69583333, 0.69791667,\n",
       "        0.65833333, 0.67708333, 0.72083333, 0.70625   , 0.69166667,\n",
       "        0.68125   , 0.68958333, 0.69166667, 0.69791667, 0.68958333,\n",
       "        0.69166667, 0.67708333, 0.69166667, 0.6875    , 0.70208333,\n",
       "        0.66875   , 0.6875    , 0.70833333, 0.67916667, 0.69583333,\n",
       "        0.68958333, 0.68333333, 0.68958333, 0.70208333, 0.69583333,\n",
       "        0.69791667, 0.68333333, 0.69583333, 0.67916667, 0.68125   ,\n",
       "        0.69166667, 0.725     , 0.66666667, 0.69166667, 0.67916667,\n",
       "        0.675     , 0.66875   , 0.68958333, 0.68958333, 0.68541667,\n",
       "        0.67291667, 0.65208333, 0.7       , 0.69166667, 0.68541667,\n",
       "        0.64166667, 0.68125   , 0.66458333, 0.67708333, 0.66458333,\n",
       "        0.63125   , 0.69166667, 0.7       , 0.69791667, 0.67916667,\n",
       "        0.65833333, 0.6875    , 0.70416667, 0.67916667, 0.69583333,\n",
       "        0.68125   , 0.69166667, 0.69166667, 0.68541667, 0.69166667,\n",
       "        0.68541667, 0.7       , 0.6875    , 0.69791667, 0.68541667,\n",
       "        0.68333333, 0.7       , 0.70208333, 0.7       , 0.70625   ,\n",
       "        0.66041667, 0.6875    , 0.70208333, 0.71041667, 0.68958333,\n",
       "        0.69583333, 0.71041667, 0.6625    , 0.68541667, 0.69166667,\n",
       "        0.625     , 0.7       , 0.70416667, 0.69583333, 0.69375   ,\n",
       "        0.68125   , 0.7       , 0.69791667, 0.69375   , 0.71875   ,\n",
       "        0.70208333, 0.71666667, 0.70416667, 0.70208333, 0.68541667,\n",
       "        0.675     , 0.6875    , 0.7       , 0.69375   , 0.69375   ,\n",
       "        0.67708333, 0.67291667, 0.67083333, 0.68958333, 0.68958333,\n",
       "        0.68333333, 0.69791667, 0.7       , 0.68541667, 0.67916667,\n",
       "        0.69166667, 0.68958333, 0.68958333, 0.71041667, 0.68958333,\n",
       "        0.66875   , 0.69375   , 0.69791667, 0.68958333, 0.70833333,\n",
       "        0.62916667, 0.66875   , 0.66666667, 0.66875   , 0.67916667,\n",
       "        0.64375   , 0.69166667, 0.67083333, 0.67916667, 0.67708333,\n",
       "        0.68125   , 0.69375   , 0.68958333, 0.70208333, 0.68541667,\n",
       "        0.68541667, 0.68958333, 0.6875    , 0.68541667, 0.69166667,\n",
       "        0.68541667, 0.66458333, 0.69791667, 0.70416667, 0.68958333,\n",
       "        0.69375   , 0.68125   , 0.70208333, 0.69791667, 0.71458333,\n",
       "        0.70625   , 0.70208333, 0.70208333, 0.71041667, 0.70416667,\n",
       "        0.675     , 0.70625   , 0.6875    , 0.69583333, 0.69583333,\n",
       "        0.65208333, 0.68958333, 0.70416667, 0.71041667, 0.69583333,\n",
       "        0.68333333, 0.69791667, 0.7125    , 0.69583333, 0.70416667,\n",
       "        0.65416667, 0.69791667, 0.69166667, 0.69375   , 0.70625   ,\n",
       "        0.65625   , 0.69166667, 0.70625   , 0.7125    , 0.7       ,\n",
       "        0.65625   , 0.70416667, 0.70833333, 0.6875    , 0.6875    ,\n",
       "        0.68125   , 0.67916667, 0.69166667, 0.68125   , 0.69166667,\n",
       "        0.63958333, 0.72083333, 0.7       , 0.69791667, 0.6875    ,\n",
       "        0.7       , 0.68333333, 0.67916667, 0.69375   , 0.6875    ,\n",
       "        0.65625   , 0.66666667, 0.67708333, 0.69166667, 0.68333333,\n",
       "        0.66041667, 0.65208333, 0.67708333, 0.6875    , 0.68541667,\n",
       "        0.65833333, 0.68958333, 0.69791667, 0.69791667, 0.70208333,\n",
       "        0.68541667, 0.67916667, 0.68958333, 0.69583333, 0.70208333,\n",
       "        0.70416667, 0.7       , 0.7       , 0.69166667, 0.68125   ,\n",
       "        0.67083333, 0.67291667, 0.675     , 0.69583333, 0.69583333,\n",
       "        0.68125   , 0.69166667, 0.6875    , 0.68125   , 0.69791667,\n",
       "        0.67291667, 0.68958333, 0.67708333, 0.70208333, 0.69166667,\n",
       "        0.68125   , 0.675     , 0.71041667, 0.7       , 0.68125   ,\n",
       "        0.69375   , 0.675     , 0.69791667, 0.7       , 0.70625   ,\n",
       "        0.69583333, 0.70208333, 0.69583333, 0.69166667, 0.69583333,\n",
       "        0.65208333, 0.68958333, 0.69375   , 0.6875    , 0.69791667,\n",
       "        0.69166667, 0.67916667, 0.70833333, 0.68958333, 0.68958333,\n",
       "        0.67708333, 0.69791667, 0.6875    , 0.69583333, 0.7       ,\n",
       "        0.70833333, 0.65833333, 0.69375   , 0.70208333, 0.70208333,\n",
       "        0.7       , 0.6875    , 0.68958333, 0.69791667, 0.66875   ,\n",
       "        0.67708333, 0.67083333, 0.675     , 0.69375   , 0.67083333,\n",
       "        0.67708333, 0.67083333, 0.69583333, 0.675     , 0.68541667,\n",
       "        0.63958333, 0.70833333, 0.68541667, 0.67291667, 0.68541667,\n",
       "        0.65416667, 0.69375   , 0.67708333, 0.68541667, 0.70625   ,\n",
       "        0.66458333, 0.67708333, 0.69583333, 0.70625   , 0.68958333,\n",
       "        0.68125   , 0.67916667, 0.7125    , 0.7       , 0.7       ,\n",
       "        0.65      , 0.6875    , 0.675     , 0.7125    , 0.70833333,\n",
       "        0.68541667, 0.70416667, 0.70416667, 0.69375   , 0.68958333,\n",
       "        0.69166667, 0.71458333, 0.68541667, 0.68958333, 0.68541667,\n",
       "        0.66875   , 0.69791667, 0.70416667, 0.68958333, 0.68541667,\n",
       "        0.69583333, 0.69583333, 0.68958333, 0.68333333, 0.69166667,\n",
       "        0.67083333, 0.70416667, 0.69166667, 0.67708333, 0.70833333,\n",
       "        0.70208333, 0.7125    , 0.69375   , 0.69791667, 0.67083333,\n",
       "        0.66041667, 0.66875   , 0.67916667, 0.69583333, 0.68333333,\n",
       "        0.68333333, 0.68125   , 0.70208333, 0.68541667, 0.6875    ,\n",
       "        0.7       , 0.6875    , 0.71875   , 0.7       , 0.70833333,\n",
       "        0.6625    , 0.64375   , 0.6625    , 0.67291667, 0.68958333,\n",
       "        0.64791667, 0.675     , 0.68541667, 0.67916667, 0.69791667,\n",
       "        0.6875    , 0.67083333, 0.69166667, 0.6875    , 0.67708333,\n",
       "        0.67291667, 0.66875   , 0.7       , 0.69791667, 0.6875    ,\n",
       "        0.675     , 0.68333333, 0.68958333, 0.69791667, 0.68958333,\n",
       "        0.66875   , 0.67916667, 0.68125   , 0.69791667, 0.68958333,\n",
       "        0.67916667, 0.69375   , 0.71875   , 0.70208333, 0.68958333,\n",
       "        0.6625    , 0.69166667, 0.69791667, 0.69583333, 0.70208333,\n",
       "        0.69375   , 0.71458333, 0.6875    , 0.69375   , 0.69166667,\n",
       "        0.6875    , 0.69375   , 0.68541667, 0.68958333, 0.7       ,\n",
       "        0.70208333, 0.7       , 0.69375   , 0.69583333, 0.68125   ,\n",
       "        0.69375   , 0.68333333, 0.6875    , 0.69791667, 0.68541667,\n",
       "        0.69791667, 0.66041667, 0.7       , 0.70833333, 0.6875    ,\n",
       "        0.65833333, 0.66041667, 0.67291667, 0.71041667, 0.68958333,\n",
       "        0.67916667, 0.70625   , 0.69791667, 0.69375   , 0.69166667,\n",
       "        0.68958333, 0.68333333, 0.68541667, 0.67291667, 0.69375   ,\n",
       "        0.63958333, 0.67291667, 0.67916667, 0.69166667, 0.68333333,\n",
       "        0.63333333, 0.68125   , 0.6625    , 0.6875    , 0.69166667,\n",
       "        0.65416667, 0.675     , 0.68958333, 0.69166667, 0.7       ,\n",
       "        0.66458333, 0.67083333, 0.68333333, 0.69166667, 0.70208333,\n",
       "        0.66875   , 0.68125   , 0.68958333, 0.69583333, 0.70208333,\n",
       "        0.71041667, 0.69791667, 0.70625   , 0.7       , 0.69791667,\n",
       "        0.67083333, 0.67291667, 0.67916667, 0.68125   , 0.68125   ,\n",
       "        0.675     , 0.69166667, 0.69375   , 0.69375   , 0.70625   ,\n",
       "        0.66875   , 0.71666667, 0.70416667, 0.70208333, 0.69583333,\n",
       "        0.68125   , 0.6875    , 0.69791667, 0.69166667, 0.6875    ,\n",
       "        0.675     , 0.68333333, 0.69791667, 0.71041667, 0.69375   ,\n",
       "        0.67291667, 0.6875    , 0.70208333, 0.69375   , 0.68541667,\n",
       "        0.69375   , 0.66041667, 0.68958333, 0.69791667, 0.69791667,\n",
       "        0.67291667, 0.69583333, 0.68958333, 0.69791667, 0.69375   ,\n",
       "        0.63958333, 0.7       , 0.675     , 0.69166667, 0.67291667,\n",
       "        0.68541667, 0.6875    , 0.675     , 0.70625   , 0.68541667]),\n",
       " 'std_test_score': array([0.04439016, 0.05605677, 0.05892557, 0.0463044 , 0.04750731,\n",
       "        0.05335937, 0.01932004, 0.04686342, 0.05720638, 0.04814258,\n",
       "        0.04903584, 0.04439016, 0.05043216, 0.04686342, 0.05605677,\n",
       "        0.025     , 0.05327797, 0.06298424, 0.04592793, 0.041978  ,\n",
       "        0.03523236, 0.06123724, 0.04350128, 0.04814258, 0.05245699,\n",
       "        0.02990146, 0.04439016, 0.03818813, 0.02375365, 0.04535738,\n",
       "        0.06353313, 0.02041241, 0.02763854, 0.06666667, 0.0344853 ,\n",
       "        0.0375    , 0.05      , 0.02224391, 0.03691676, 0.04723243,\n",
       "        0.02871677, 0.04399732, 0.04399732, 0.03385016, 0.03952847,\n",
       "        0.05170697, 0.05914612, 0.05535554, 0.03875224, 0.04991312,\n",
       "        0.04956407, 0.02185018, 0.04389856, 0.05043216, 0.04686342,\n",
       "        0.041978  , 0.02224391, 0.04516559, 0.03644345, 0.03186887,\n",
       "        0.06620937, 0.02124591, 0.05229125, 0.03254271, 0.04039733,\n",
       "        0.02411633, 0.02282177, 0.06159061, 0.02990146, 0.025     ,\n",
       "        0.07711148, 0.0372678 , 0.04814258, 0.0463044 , 0.03761556,\n",
       "        0.04903584, 0.02551552, 0.04639804, 0.03267581, 0.05628857,\n",
       "        0.04639804, 0.07003223, 0.07383352, 0.05987545, 0.0601647 ,\n",
       "        0.02019867, 0.03703414, 0.04535738, 0.05311479, 0.04768968,\n",
       "        0.02763854, 0.05077524, 0.05335937, 0.0389756 , 0.05833333,\n",
       "        0.03397814, 0.02585349, 0.04135299, 0.04487637, 0.04399732,\n",
       "        0.05077524, 0.05286907, 0.04289846, 0.04991312, 0.05170697,\n",
       "        0.03644345, 0.025     , 0.05758448, 0.03333333, 0.03131937,\n",
       "        0.03397814, 0.03186887, 0.02144923, 0.05162297, 0.04007372,\n",
       "        0.03510896, 0.04061164, 0.02585349, 0.04028975, 0.05043216,\n",
       "        0.03584302, 0.06366961, 0.04350128, 0.0372678 , 0.05448624,\n",
       "        0.04823265, 0.06002025, 0.04686342, 0.04320092, 0.04545297,\n",
       "        0.05286907, 0.05892557, 0.03423266, 0.01530931, 0.04439016,\n",
       "        0.04535738, 0.0529511 , 0.05034602, 0.04868051, 0.03919768,\n",
       "        0.04750731, 0.08400769, 0.06763618, 0.04991312, 0.04145781,\n",
       "        0.04956407, 0.02990146, 0.05392575, 0.03818813, 0.04289846,\n",
       "        0.04768968, 0.04028975, 0.04723243, 0.05644257, 0.04135299,\n",
       "        0.04448783, 0.05914612, 0.06052433, 0.05128556, 0.05720638,\n",
       "        0.03875224, 0.05128556, 0.06922187, 0.06109533, 0.06953466,\n",
       "        0.06095308, 0.03333333, 0.06298424, 0.04419417, 0.04028975,\n",
       "        0.05368374, 0.04516559, 0.041978  , 0.03919768, 0.04768968,\n",
       "        0.03061862, 0.06339635, 0.03761556, 0.06298424, 0.04448783,\n",
       "        0.05682576, 0.02019867, 0.05187458, 0.0535218 , 0.03118048,\n",
       "        0.04956407, 0.05605677, 0.04592793, 0.03385016, 0.04487637,\n",
       "        0.00833333, 0.06588078, 0.04448783, 0.05644257, 0.05408648,\n",
       "        0.05327797, 0.03320287, 0.05535554, 0.03186887, 0.041978  ,\n",
       "        0.05965759, 0.01792151, 0.04956407, 0.0344853 , 0.04093101,\n",
       "        0.02841288, 0.05644257, 0.05103104, 0.04956407, 0.04419417,\n",
       "        0.04686342, 0.04389856, 0.03397814, 0.04448783, 0.05605677,\n",
       "        0.03254271, 0.03952847, 0.05605677, 0.02517301, 0.03333333,\n",
       "        0.05270463, 0.04497299, 0.04093101, 0.03510896, 0.03632416,\n",
       "        0.03584302, 0.03841477, 0.04187448, 0.04082483, 0.04439016,\n",
       "        0.05043216, 0.04723243, 0.04535738, 0.04903584, 0.04238956,\n",
       "        0.07228896, 0.04399732, 0.05855612, 0.06052433, 0.04218428,\n",
       "        0.04399732, 0.03807431, 0.02185018, 0.04903584, 0.06332785,\n",
       "        0.01666667, 0.03703414, 0.04145781, 0.04487637, 0.05103104,\n",
       "        0.04686342, 0.01932004, 0.05120086, 0.04823265, 0.04340139,\n",
       "        0.05682576, 0.03691676, 0.03359274, 0.04991312, 0.04093101,\n",
       "        0.05644257, 0.03047654, 0.04320092, 0.04823265, 0.03919768,\n",
       "        0.02338536, 0.03131937, 0.02990146, 0.04007372, 0.03523236,\n",
       "        0.01666667, 0.01559024, 0.03761556, 0.05527708, 0.041978  ,\n",
       "        0.04991312, 0.01530931, 0.03423266, 0.03632416, 0.05870418,\n",
       "        0.03644345, 0.04187448, 0.02517301, 0.02901748, 0.04340139,\n",
       "        0.0557462 , 0.04166667, 0.04868051, 0.05488308, 0.04093101,\n",
       "        0.05408648, 0.05432669, 0.05914612, 0.04448783, 0.03047654,\n",
       "        0.06284626, 0.04350128, 0.03047654, 0.02684187, 0.03919768,\n",
       "        0.05432669, 0.0602368 , 0.04166667, 0.05392575, 0.03294039,\n",
       "        0.03985651, 0.06088183, 0.03461093, 0.02243819, 0.0477806 ,\n",
       "        0.03267581, 0.06088183, 0.04439016, 0.04796194, 0.05392575,\n",
       "        0.02411633, 0.04592793, 0.05720638, 0.03584302, 0.05311479,\n",
       "        0.05392575, 0.02375365, 0.04061164, 0.03200477, 0.04868051,\n",
       "        0.05335937, 0.06959705, 0.0488585 , 0.04007372, 0.03510896,\n",
       "        0.03047654, 0.025     , 0.05855612, 0.05628857, 0.04686342,\n",
       "        0.03691676, 0.02901748, 0.03691676, 0.04487637, 0.04299952,\n",
       "        0.02338536, 0.04439016, 0.04723243, 0.04545297, 0.03875224,\n",
       "        0.06990817, 0.03131937, 0.04238956, 0.0375    , 0.05162297,\n",
       "        0.060596  , 0.04299952, 0.05145454, 0.04399732, 0.05229125,\n",
       "        0.0557462 , 0.02825971, 0.02282177, 0.03930825, 0.03703414,\n",
       "        0.07021791, 0.02825971, 0.05162297, 0.03118048, 0.05253967,\n",
       "        0.03584302, 0.06088183, 0.0186339 , 0.0344853 , 0.03807431,\n",
       "        0.03632416, 0.0477806 , 0.03254271, 0.04093101, 0.04238956,\n",
       "        0.04592793, 0.03118048, 0.05170697, 0.05628857, 0.05929271,\n",
       "        0.04823265, 0.06366961, 0.03784563, 0.05245699, 0.04903584,\n",
       "        0.06972167, 0.04419417, 0.06073908, 0.04187448, 0.03320287,\n",
       "        0.02185018, 0.05870418, 0.03267581, 0.04350128, 0.05335937,\n",
       "        0.0344853 , 0.05270463, 0.05327797, 0.03547789, 0.03632416,\n",
       "        0.05017331, 0.0602368 , 0.05720638, 0.06607813, 0.05043216,\n",
       "        0.03547789, 0.02841288, 0.05644257, 0.02825971, 0.0463044 ,\n",
       "        0.06166104, 0.05392575, 0.0463044 , 0.04912428, 0.03320287,\n",
       "        0.04723243, 0.01932004, 0.04611655, 0.02748105, 0.04238956,\n",
       "        0.03320287, 0.01976424, 0.04340139, 0.05120086, 0.05408648,\n",
       "        0.03131937, 0.02901748, 0.04350128, 0.03186887, 0.05204165,\n",
       "        0.02144923, 0.03294039, 0.01909407, 0.03584302, 0.04468252,\n",
       "        0.05368374, 0.04093101, 0.03061862, 0.02517301, 0.04535738,\n",
       "        0.03397814, 0.05      , 0.04859127, 0.04535738, 0.04723243,\n",
       "        0.04135299, 0.06180165, 0.04299952, 0.0463044 , 0.05077524,\n",
       "        0.02019867, 0.04439016, 0.02124591, 0.03761556, 0.02763854,\n",
       "        0.04823265, 0.03461093, 0.03131937, 0.04796194, 0.02551552,\n",
       "        0.01932004, 0.03131937, 0.02243819, 0.03841477, 0.041978  ,\n",
       "        0.03930825, 0.05870418, 0.04028975, 0.05943893, 0.02990146,\n",
       "        0.06201198, 0.05043216, 0.04956407, 0.04082483, 0.05392575,\n",
       "        0.03320287, 0.04516559, 0.05270463, 0.05527708, 0.0389756 ,\n",
       "        0.0529511 , 0.04723243, 0.03875224, 0.04249183, 0.03864008,\n",
       "        0.04028975, 0.03385016, 0.0601647 , 0.04238956, 0.05705443,\n",
       "        0.07186745, 0.04823265, 0.03461093, 0.05145454, 0.03159531,\n",
       "        0.03985651, 0.04535738, 0.04340139, 0.05511982, 0.03547789,\n",
       "        0.03691676, 0.04299952, 0.06229132, 0.0488585 , 0.04859127,\n",
       "        0.0375    , 0.02411633, 0.03397814, 0.03784563, 0.02901748,\n",
       "        0.02667968, 0.05914612, 0.03294039, 0.03930825, 0.0463044 ,\n",
       "        0.05043216, 0.04039733, 0.02946278, 0.04583333, 0.02990146,\n",
       "        0.06607813, 0.03761556, 0.04007372, 0.02144923, 0.0529511 ,\n",
       "        0.04564355, 0.03818813, 0.0344853 , 0.04859127, 0.04135299,\n",
       "        0.05496211, 0.03254271, 0.04093101, 0.01909407, 0.04732424,\n",
       "        0.03523236, 0.05803495, 0.04516559, 0.0389756 , 0.04135299,\n",
       "        0.03227486, 0.04956407, 0.02901748, 0.0389756 , 0.04564355,\n",
       "        0.05796012, 0.06705615, 0.03761556, 0.02411633, 0.03572173,\n",
       "        0.02585349, 0.07465197, 0.04611655, 0.02517301, 0.04592793,\n",
       "        0.03974747, 0.02916667, 0.03572173, 0.041978  , 0.03333333,\n",
       "        0.03818813, 0.03267581, 0.04768968, 0.05987545, 0.05253967,\n",
       "        0.02975595, 0.0529511 , 0.03523236, 0.04061164, 0.0477806 ,\n",
       "        0.06159061, 0.03047654, 0.03691676, 0.04956407, 0.03864008,\n",
       "        0.03632416, 0.04956407, 0.03875224, 0.05      , 0.03584302,\n",
       "        0.02224391, 0.04448783, 0.03864008, 0.0601647 , 0.04823265,\n",
       "        0.02319902, 0.04516559, 0.04028975, 0.04289846, 0.05060399,\n",
       "        0.05914612, 0.03267581, 0.04028975, 0.03523236, 0.03131937,\n",
       "        0.03632416, 0.02338536, 0.04249183, 0.03523236, 0.04535738,\n",
       "        0.03919768, 0.03186887, 0.03584302, 0.03131937, 0.04238956,\n",
       "        0.05376453, 0.02946278, 0.0389756 , 0.02429563, 0.04750731,\n",
       "        0.05644257, 0.02916667, 0.03608439, 0.04487637, 0.04912428,\n",
       "        0.02990146, 0.04061164, 0.05253967, 0.03523236, 0.03320287,\n",
       "        0.04912428, 0.01692508, 0.03186887, 0.03294039, 0.03359274,\n",
       "        0.03818813, 0.04439016, 0.04340139, 0.05187458, 0.04497299,\n",
       "        0.05      , 0.03118048, 0.01792151, 0.05651942, 0.0529511 ,\n",
       "        0.02124591, 0.02871677, 0.05245699, 0.03047654, 0.05408648]),\n",
       " 'rank_test_score': array([632, 632, 355, 517, 498, 597, 425, 221, 571, 317, 473, 414, 537,\n",
       "        425, 202, 568, 623, 390,  77, 425, 597, 298,  11,  59,  44,  64,\n",
       "        298,  83, 171, 390, 498, 537,  11, 298, 116, 116, 537, 317,  44,\n",
       "        414, 350, 592,   2,  44, 147, 549, 221,  77,  17,  44, 559,  37,\n",
       "        317, 425, 221, 638, 414, 355,  64, 202, 504, 473,   5,  22, 255,\n",
       "        317, 350,  44, 255, 116, 355, 355, 317, 202, 221, 517, 387,  83,\n",
       "        447, 355, 636, 582, 537, 456, 473, 632, 597, 317, 504, 317, 425,\n",
       "        493, 221, 147, 187, 626,  32, 517, 317, 221, 517, 116, 472, 116,\n",
       "         64, 425,  44, 116,  92,  92, 255, 473, 255, 202, 171, 608, 504,\n",
       "          3,  44, 255, 456, 317, 255, 147, 298, 255, 504, 255, 355,  92,\n",
       "        571, 355,  33, 473, 218, 317, 425, 317,  83, 187, 171, 425, 187,\n",
       "        473, 469, 255,   1, 582, 255, 473, 517, 571, 298, 317, 390, 537,\n",
       "        617, 116, 255, 390, 627, 447, 588, 504, 586, 636, 255, 116, 147,\n",
       "        473, 608, 355,  64, 493, 202, 447, 255, 255, 390, 255, 414, 116,\n",
       "        355, 171, 390, 425, 116,  92, 112,  44, 597, 355,  83,  23, 317,\n",
       "        202,  23, 592, 390, 255, 640, 116,  64, 187, 221, 447, 116, 147,\n",
       "        221,   7,  92,   9,  64,  92, 390, 517, 350, 116, 221, 221, 498,\n",
       "        549, 559, 317, 349, 425, 171, 116, 414, 473, 255, 317, 317,  23,\n",
       "        298, 568, 221, 147, 298,  37, 638, 571, 582, 571, 473, 624, 255,\n",
       "        559, 473, 504, 456, 221, 298,  92, 390, 390, 317, 355, 414, 255,\n",
       "        390, 588, 147,  64, 317, 221, 456,  92, 171,  11,  44,  92,  92,\n",
       "         23,  77, 517,  59, 350, 187, 202, 617, 317,  64,  23, 202, 425,\n",
       "        147,  16, 202,  64, 614, 147, 255, 252,  44, 611, 255,  44,  17,\n",
       "        116, 611,  64,  33, 355, 355, 447, 473, 255, 456, 255, 630,   4,\n",
       "        112, 147, 350, 116, 425, 493, 221, 355, 611, 585, 504, 255, 425,\n",
       "        597, 617, 498, 355, 390, 606, 298, 171, 171,  92, 390, 473, 317,\n",
       "        202,  83,  77, 116, 116, 255, 456, 559, 549, 536, 187, 202, 469,\n",
       "        255, 387, 456, 171, 537, 298, 504,  92, 255, 456, 517,  23, 116,\n",
       "        447, 221, 517, 147, 116,  44, 202, 111, 187, 255, 202, 617, 317,\n",
       "        221, 355, 147, 255, 493,  33, 298, 317, 504, 171, 355, 202, 116,\n",
       "         37, 608, 252,  83,  92, 116, 355, 298, 147, 571, 498, 559, 517,\n",
       "        221, 556, 504, 556, 202, 517, 390, 630,  33, 390, 549, 390, 614,\n",
       "        221, 504, 414,  44, 588, 498, 202,  59, 317, 456, 473,  17, 116,\n",
       "        112, 621, 355, 517,  17,  37, 414,  64,  77, 221, 298, 255,  11,\n",
       "        414, 317, 414, 571, 147,  64, 317, 390, 187, 187, 317, 425, 255,\n",
       "        559,  77, 255, 504,  37,  92,  21, 221, 147, 556, 597, 571, 473,\n",
       "        187, 425, 425, 456,  92, 390, 355, 116, 355,   7, 116,  37, 592,\n",
       "        624, 591, 537, 317, 622, 517, 390, 493, 171, 355, 559, 255, 355,\n",
       "        504, 549, 571, 116, 171, 355, 517, 425, 298, 147, 298, 568, 473,\n",
       "        456, 147, 317, 473, 221,   5,  92, 317, 592, 255, 147, 187,  92,\n",
       "        221,  11, 355, 221, 255, 387, 219, 390, 298, 112,  83, 116, 221,\n",
       "        187, 469, 221, 425, 355, 147, 390, 171, 597, 116,  37, 355, 606,\n",
       "        597, 537,  23, 298, 473,  59, 171, 221, 255, 298, 425, 414, 537,\n",
       "        221, 628, 549, 473, 255, 425, 635, 447, 596, 355, 255, 616, 517,\n",
       "        317, 255, 116, 586, 559, 425, 255,  92, 571, 447, 317, 187,  92,\n",
       "         23, 147,  44, 116, 147, 559, 537, 473, 456, 456, 517, 255, 221,\n",
       "        219,  59, 571,   9,  64,  83, 187, 447, 355, 147, 255, 355, 517,\n",
       "        425, 171,  23, 221, 537, 355,  83, 221, 390, 221, 597, 298, 171,\n",
       "        147, 549, 187, 317, 147, 252, 628, 116, 517, 255, 537, 390, 355,\n",
       "        517,  44, 390])}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366239e6-bb1a-4d0d-8955-086d4710fcba",
   "metadata": {},
   "source": [
    "Verificando os melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "915ec2cd-ae35-4a60-a9a7-dc6ce41ce040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 20,\n",
       " 'min_samples_leaf': 15,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b835572-9b2d-4d28-93de-e31305347dcc",
   "metadata": {},
   "source": [
    "Verificando o melhor Score,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2e67ba53-8611-421d-8147-f6a1c156ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664a623-e1fb-40ec-827e-0b11006ccf67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
